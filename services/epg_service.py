"""
EPG (Electronic Program Guide) Service

Handles parsing XMLTV data, matching EPG channels to our channels,
and managing EPG sources.

XMLTV Channel ID Formats:
- Provider XMLTV: Typically textual like "ESPN.us", "AntennaTV.us", "BBC1.uk"
- Schedules Direct: "I{station_id}.json.schedulesdirect.org" (e.g., "I10021.json.schedulesdirect.org")
- Generic: Can be any string identifier

Matching Strategy:
Since XMLTV IDs from providers are textual (callsign-based) and Schedules Direct
uses numeric station IDs, we match channels using:
1. Exact callsign matching (extracting from XMLTV ID format)
2. Exact name matching
3. Fuzzy name matching

East/West Channel Handling:
Many US channels have east and west coast feeds (e.g., "HBO East", "HBO West").
EPG data often only contains listings for the east feed or without geographic identifier.
West feed EPG is generated by shifting east feed times by -3 hours.
"""
import gzip
import io
import json
import logging
import re
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from difflib import SequenceMatcher
from typing import Any, Dict, Iterator, List, Optional, Set, Tuple

from models import Channel, ChannelEpgMapping, ChannelTag, EpgChannel, EpgSource, FccFacility, Tag, db
from services.epg_match_rules_service import EpgMatchRulesService

logger = logging.getLogger(__name__)

# Major broadcast networks that should match EPG network channels
MAJOR_BROADCAST_NETWORKS = {"ABC", "NBC", "CBS", "FOX", "PBS", "CW", "ION"}

# Fallback generic EPG channel IDs for networks without local market coverage
# Used as last resort when no local station EPG data is available
# Maps network name to (epg_channel_id, display_name) tuples in priority order
NETWORK_FALLBACK_EPG_IDS = {
    "CW": [("CW.us2", "CW")],
    # Add more networks as generic feeds become available
    # "ABC": [("ABC.National.Feed.us2", "ABC National Feed")],
    # "CBS": [("cbs-news", "CBS News 24/7")],  # Not a real affiliate substitute
    # "NBC": [("nbc-news-now", "NBC News NOW")],  # Not a real affiliate substitute
}

# PPV (Pay-Per-View) category patterns
# PPV channels update their names dynamically when events are scheduled,
# so they should not have traditional EPG mappings.
# These patterns match the category NAME (not channel names).
# Based on analysis of actual IPTV provider data, PPV categories typically
# have "PPV" somewhere in their category name.
PPV_CATEGORY_PATTERNS = [
    r"\bPPV\b",  # Most common: "UK| DAZN PPV", "US| ESPN+ PPV", "NL| MAX PPV"
    r"PAY[\s-]?PER[\s-]?VIEW",  # "Pay-Per-View", "Pay Per View", "PAY-PER-VIEW"
    # Note: We intentionally don't match generic "EVENT" categories as those
    # are often legitimate sports channels with regular EPG data.
    # PPV categories almost always have "PPV" in the name explicitly.
]

# PPV placeholder name patterns
# When no event is scheduled, PPV channels have generic placeholder names
# When an event IS scheduled, the provider changes the channel name to the event title
# We detect "inactive" PPV channels by matching these placeholder patterns.
#
# Based on analysis of actual IPTV provider channel names:
# - Inactive: "UK: DAZN PPV 1 ᴿᴬᵂ", "US: ESPN PLUS 01 PPV", "NL: MAX PPV 1 - NO EVENT STREAMING -"
# - Active: "UK: DAZN PPV 1 - UFC 300: Jones vs Miocic", "EPL 01: 20:00 Manchester United vs Newcastle"
PPV_PLACEHOLDER_PATTERNS = [
    # Explicit "NO EVENT" markers (very common)
    r"NO\s+EVENT\s+STREAMING",  # "NO EVENT STREAMING", "- NO EVENT STREAMING -"
    r"NO\s+EVENT\s+SCHEDULED",  # Less common variant
    r"NO\s+SCHEDULED\s+EVENT",  # Another variant
    # Basic numbered PPV channels without event info: "PPV 1", "PPV 2", "PPV-01"
    r"^(?:[A-Z]{2}[:\s])?(?:[A-Z0-9\+\s]+)?PPV[\s\-]*\d+\s*(?:ᴿᴬᵂ|ᴴᴰ|⁴ᴷ|4K|HD|SD)?$",
    # Event channels with just numbers: "EVENT 1", "VIDIO EVENT 1"
    r"EVENT\s+\d+\s*$",
    # Empty event slots: "PPV 1 -", "UFC 09:", ":MAX NL 05"
    r"(?:PPV|UFC|NBA|NHL|MLB|MLS|WNBA)\s*\d+\s*[:\-]?\s*$",
    # Placeholder colon format: ":Viaplay NL  14", ":MAX US 03"
    r"^:?\s*(?:[A-Z]+\s+)?(?:Viaplay|MAX|ESPN)\s+[A-Z]{2}\s+\d+\s*$",
    # Coming Soon/TBA placeholders
    r"^(?:COMING\s+SOON|TBA|TBD|OFFLINE).*$",
    # Florugby/generic sport numbered: "Florugby 00", "Florugby 01"
    r"^[A-Za-z]+\s+\d{2}\s*$",
    # Empty fixture slots: "GaaGo Fixtures 10:", "LOI 06 |"
    r"Fixtures?\s+\d+\s*[:\|]?\s*$",
    # NIFL/GAA empty: "NIFL 5 |", "ULSTER GAA 06 |"
    r"(?:NIFL|GAA|ULSTER)\s*\d+\s*\|?\s*$",
]


def extract_callsign_from_xmltv_id(xmltv_id: str) -> Optional[str]:
    """
    Extract a callsign/identifier from various XMLTV channel ID formats.

    Args:
        xmltv_id: The XMLTV channel ID string

    Returns:
        Extracted callsign or None if extraction fails

    Examples:
        "ESPN.us" -> "ESPN"
        "AntennaTV.us" -> "AntennaTV"
        "I10021.json.schedulesdirect.org" -> "10021"
        "BBC One" -> "BBC One"
        "CNN" -> "CNN"
    """
    if not xmltv_id:
        return None

    # Pattern 1: Schedules Direct format (I{station_id}.json.schedulesdirect.org)
    sd_match = re.match(r"I(\d+)\.json\.schedulesdirect\.org", xmltv_id, re.IGNORECASE)
    if sd_match:
        return sd_match.group(1)

    # Pattern 2: CALLSIGN.country or CALLSIGN.tld (e.g., ESPN.us, BBC1.uk)
    # Match alphanumeric callsign before the first dot
    dot_match = re.match(r"^([A-Za-z0-9]+(?:[A-Za-z0-9\-]*[A-Za-z0-9])?)\.(?:[a-z]{2,}|[A-Z]{2,})$", xmltv_id)
    if dot_match:
        return dot_match.group(1)

    # Pattern 3: Return as-is if it looks like a simple callsign (no dots, reasonable length)
    if "." not in xmltv_id and len(xmltv_id) <= 20:
        return xmltv_id

    # Pattern 4: Try to extract first segment before any dot
    if "." in xmltv_id:
        first_segment = xmltv_id.split(".")[0]
        if first_segment and len(first_segment) >= 2:
            return first_segment

    return xmltv_id


def make_sd_xmltv_id(station_id: str) -> str:
    """
    Create a Schedules Direct style XMLTV channel ID.

    Args:
        station_id: The numeric Schedules Direct station ID

    Returns:
        XMLTV-format ID like "I10021.json.schedulesdirect.org"
    """
    return f"I{station_id}.json.schedulesdirect.org"


def normalize_xmltv_url(url: str) -> str:
    """
    Normalize an XMLTV URL to ensure it returns raw content.

    Converts GitHub blob URLs to raw.githubusercontent.com URLs.

    Args:
        url: The URL to normalize

    Returns:
        The normalized URL

    Examples:
        "https://github.com/user/repo/blob/main/guide.xml"
        -> "https://raw.githubusercontent.com/user/repo/main/guide.xml"
    """
    # Convert GitHub blob URLs to raw URLs
    github_blob_pattern = r"^https?://github\.com/([^/]+)/([^/]+)/blob/(.+)$"
    match = re.match(github_blob_pattern, url)
    if match:
        owner, repo, path = match.groups()
        return f"https://raw.githubusercontent.com/{owner}/{repo}/{path}"
    return url


def is_ppv_channel(channel: Channel) -> bool:
    """
    Determine if a channel is a Pay-Per-View (PPV) channel.

    PPV channels dynamically update their names when events are scheduled,
    so they should not have traditional EPG mappings. Instead, they should
    be excluded from automatic EPG matching.

    Detection is based on category name patterns.

    Args:
        channel: Channel to check

    Returns:
        True if the channel appears to be a PPV channel

    Examples:
        Category "PPV EVENTS" -> True
        Category "US| PAY-PER-VIEW" -> True
        Category "UFC EVENTS" -> True
        Category "US| ENTERTAINMENT" -> False
    """
    if not channel.category:
        return False

    category_name = channel.category.category_name.upper()

    for pattern in PPV_CATEGORY_PATTERNS:
        if re.search(pattern, category_name, re.IGNORECASE):
            logger.debug(
                f"Channel '{channel.name}' identified as PPV "
                f"(category='{channel.category.category_name}', pattern='{pattern}')"
            )
            return True

    return False


def is_ppv_category(category_name: str) -> bool:
    """
    Determine if a category name indicates a PPV (Pay-Per-View) category.

    PPV channels update their names dynamically when events are scheduled,
    so they should not have traditional EPG mappings. This function checks
    if a category name matches PPV patterns.

    Args:
        category_name: The category name to check

    Returns:
        True if the category appears to be a PPV category

    Examples:
        "UK| DAZN PPV" -> True
        "US| ESPN+ PPV ⱽᴵᴾ" -> True
        "NL| MAX PPV" -> True
        "UK| SPORTS" -> False
        "US| ENTERTAINMENT" -> False
    """
    if not category_name:
        return False

    upper_name = category_name.upper()

    for pattern in PPV_CATEGORY_PATTERNS:
        if re.search(pattern, upper_name, re.IGNORECASE):
            return True

    return False


def is_ppv_placeholder_name(name: str) -> bool:
    """
    Check if a channel name is a PPV placeholder (no event scheduled).

    PPV channels from providers have placeholder names like "PPV 1", "PPV EVENT 2"
    when no event is scheduled. When an event IS scheduled, the provider changes
    the channel name to the actual event title (e.g., "UFC 300: Main Event").

    This function detects placeholder names to determine if a PPV channel
    should be hidden (placeholder) or shown (actual event scheduled).

    Args:
        name: The channel name to check

    Returns:
        True if the name matches a placeholder pattern (no event)
        False if the name appears to be an actual event title

    Examples:
        "UK: DAZN PPV 1 - NO EVENT STREAMING -" -> True (placeholder)
        "UFC 09:" -> True (placeholder)
        "UK: DAZN PPV 1 - UFC 300: Jones vs Miocic" -> False (actual event)
        "BOXING: Fury vs Joshua" -> False (actual event)
    """
    if not name:
        return True  # Empty name is treated as placeholder

    # Normalize the name for comparison
    normalized = name.strip().upper()

    # Check against placeholder patterns
    # Use re.search() to find patterns anywhere in the string
    for pattern in PPV_PLACEHOLDER_PATTERNS:
        if re.search(pattern, normalized, re.IGNORECASE):
            logger.debug(f"Channel name '{name}' matches placeholder pattern '{pattern}'")
            return True

    return False


def get_ppv_event_title(channel: Channel) -> Optional[str]:
    """
    Extract the event title from a PPV channel that has an active event.

    When a PPV channel has an event scheduled, the channel name becomes
    the event title. This function returns that title for use in EPG generation.

    Args:
        channel: The PPV channel to extract the event title from

    Returns:
        The event title if the channel has an active event, None if placeholder

    Examples:
        Channel name "UFC 300: Main Event" -> "UFC 300: Main Event"
        Channel name "PPV 1" -> None (placeholder)
    """
    if not channel.name:
        return None

    if is_ppv_placeholder_name(channel.name):
        return None

    # The channel name IS the event title
    return channel.name.strip()


# ============================================================================
# Channel Link EPG Handling
# ============================================================================

# Tag names that indicate east/west variants (used for auto-detection during sync)
EAST_TAGS = {"EAST", "E", "ET", "EST", "EASTERN"}
WEST_TAGS = {"WEST", "W", "PT", "PST", "PACIFIC", "WESTERN"}


def shift_xmltv_time(time_str: str, hours: int) -> str:
    """
    Shift an XMLTV datetime string by a number of hours.

    XMLTV format: YYYYMMDDHHmmss +ZZZZ (e.g., "20231215140000 +0000")

    Args:
        time_str: XMLTV datetime string
        hours: Number of hours to shift (negative for earlier)

    Returns:
        Shifted XMLTV datetime string
    """
    if not time_str:
        return time_str

    # Split off timezone if present
    parts = time_str.split()
    datetime_part = parts[0]
    tz_part = parts[1] if len(parts) > 1 else "+0000"

    # Parse datetime
    try:
        if len(datetime_part) >= 14:
            dt = datetime.strptime(datetime_part[:14], "%Y%m%d%H%M%S")
        elif len(datetime_part) >= 12:
            dt = datetime.strptime(datetime_part[:12], "%Y%m%d%H%M")
        elif len(datetime_part) >= 8:
            dt = datetime.strptime(datetime_part[:8], "%Y%m%d")
        else:
            return time_str
    except ValueError:
        return time_str

    # Apply shift
    dt = dt + timedelta(hours=hours)

    # Format back to XMLTV format
    return f"{dt.strftime('%Y%m%d%H%M%S')} {tz_part}"


def decompress_content(content: bytes) -> bytes:
    """
    Decompress gzipped content if necessary.

    Args:
        content: Raw bytes that may be gzip-compressed

    Returns:
        Decompressed bytes, or original content if not gzipped
    """
    # Check for gzip magic bytes
    if content[:2] == b"\x1f\x8b":
        try:
            return gzip.decompress(content)
        except gzip.BadGzipFile:
            logger.warning("Content has gzip header but failed to decompress")
            return content
    return content


def get_decompressing_stream(content: bytes) -> io.BufferedIOBase:
    """
    Get a file-like object for reading content, with streaming decompression if gzipped.

    Args:
        content: Raw bytes that may be gzip-compressed

    Returns:
        A file-like object for reading the (decompressed) content
    """
    # Check for gzip magic bytes
    if content[:2] == b"\x1f\x8b":
        # Use streaming gzip decompression
        return gzip.GzipFile(fileobj=io.BytesIO(content), mode="rb")
    return io.BytesIO(content)


class EpgService:
    """Service for managing EPG data and channel matching"""

    @staticmethod
    def parse_xmltv_streaming(xml_content: bytes) -> Iterator[Tuple[str, Dict]]:
        """
        Parse XMLTV content using streaming parser for memory efficiency.
        Yields channel and programme elements one at a time.

        Args:
            xml_content: Raw XMLTV XML bytes (may be gzip-compressed)

        Yields:
            Tuples of (element_type, data) where element_type is 'channel' or 'programme'
        """
        stream = get_decompressing_stream(xml_content)

        try:
            # Use iterparse for memory-efficient parsing
            context = ET.iterparse(stream, events=("end",))

            for event, elem in context:
                if elem.tag == "channel":
                    channel_id = elem.get("id")
                    if channel_id:
                        display_names = []
                        for dn in elem.findall("display-name"):
                            if dn.text:
                                display_names.append(dn.text.strip())

                        icon_url = None
                        icon_elem = elem.find("icon")
                        if icon_elem is not None:
                            icon_url = icon_elem.get("src")

                        url = None
                        url_elem = elem.find("url")
                        if url_elem is not None and url_elem.text:
                            url = url_elem.text.strip()

                        yield (
                            "channel",
                            {
                                "channel_id": channel_id,
                                "display_names": display_names,
                                "display_name": display_names[0] if display_names else channel_id,
                                "icon_url": icon_url,
                                "url": url,
                            },
                        )

                    # Clear element to free memory
                    elem.clear()

                elif elem.tag == "programme":
                    channel_id = elem.get("channel")
                    if channel_id:
                        yield (
                            "programme",
                            {
                                "channel": channel_id,
                                "start": elem.get("start"),
                                "stop": elem.get("stop"),
                            },
                        )

                    # Clear element to free memory
                    elem.clear()

                # Also clear any ancestors to prevent memory buildup
                # This is needed because iterparse keeps a reference to parent elements
                if elem.tag in ("channel", "programme"):
                    # Clear the element's tail text
                    elem.tail = None

        except ET.ParseError as e:
            logger.error(f"Failed to parse XMLTV: {e}")
            raise ValueError(f"Invalid XMLTV XML: {e}")
        finally:
            stream.close()

    @staticmethod
    def parse_xmltv(xml_content: bytes) -> Dict:
        """
        Parse XMLTV content and extract channel information.

        Uses streaming parser internally for memory efficiency with large files.

        Args:
            xml_content: Raw XMLTV XML bytes (may be gzip-compressed)

        Returns:
            Dict with 'channels' list and 'programs_by_channel' dict
        """
        channels = []
        programs_by_channel: Dict[str, List[Dict]] = {}

        for element_type, data in EpgService.parse_xmltv_streaming(xml_content):
            if element_type == "channel":
                channels.append(data)
                programs_by_channel[data["channel_id"]] = []
            elif element_type == "programme":
                channel_id = data["channel"]
                if channel_id in programs_by_channel:
                    programs_by_channel[channel_id].append(
                        {
                            "start": data["start"],
                            "stop": data["stop"],
                        }
                    )

        return {
            "channels": channels,
            "programs_by_channel": programs_by_channel,
        }

    @staticmethod
    def sync_epg_source(source: EpgSource, xml_content: bytes) -> Dict:
        """
        Sync EPG data from XMLTV content into the database.

        Uses streaming parser for memory efficiency with large files.

        Args:
            source: The EpgSource to sync
            xml_content: Raw XMLTV XML bytes

        Returns:
            Dict with sync statistics
        """
        stats = {
            "channels_added": 0,
            "channels_updated": 0,
            "channels_removed": 0,
            "total_programs": 0,
        }

        now = datetime.utcnow()
        seen_channel_ids: Set[str] = set()

        # Track channel data and program stats as we stream
        # We only keep essential info in memory, not all program details
        channel_data_map: Dict[str, Dict] = {}
        channel_program_stats: Dict[str, Dict] = {}  # channel_id -> {count, first_time, last_time}

        # Stream through the XMLTV content
        try:
            for element_type, data in EpgService.parse_xmltv_streaming(xml_content):
                if element_type == "channel":
                    channel_id = data["channel_id"]
                    if channel_id in channel_data_map:
                        # Handle duplicate channel entries by merging display names
                        existing = channel_data_map[channel_id]
                        existing_names = existing.get("display_names", [])
                        new_names = data.get("display_names", [])
                        merged_names = list(dict.fromkeys(existing_names + new_names))
                        existing["display_names"] = merged_names
                        if not existing.get("icon_url") and data.get("icon_url"):
                            existing["icon_url"] = data.get("icon_url")
                        if not existing.get("url") and data.get("url"):
                            existing["url"] = data.get("url")
                        logger.debug(f"Merged duplicate channel ID '{channel_id}' in XMLTV data")
                    else:
                        channel_data_map[channel_id] = data
                        channel_program_stats[channel_id] = {
                            "count": 0,
                            "first_time": None,
                            "last_time": None,
                        }
                    seen_channel_ids.add(channel_id)

                elif element_type == "programme":
                    channel_id = data["channel"]
                    if channel_id in channel_program_stats:
                        prog_stats = channel_program_stats[channel_id]
                        prog_stats["count"] += 1
                        stats["total_programs"] += 1

                        # Track time range without storing all times
                        for time_field in ("start", "stop"):
                            time_str = data.get(time_field)
                            if time_str:
                                try:
                                    t = EpgService._parse_xmltv_time(time_str)
                                    if t:
                                        if prog_stats["first_time"] is None or t < prog_stats["first_time"]:
                                            prog_stats["first_time"] = t
                                        if prog_stats["last_time"] is None or t > prog_stats["last_time"]:
                                            prog_stats["last_time"] = t
                                except Exception:
                                    pass

        except ValueError as e:
            source.last_sync = datetime.utcnow()
            source.last_sync_status = "error"
            source.last_sync_message = str(e)
            db.session.commit()
            raise

        # Track channels we've already processed in THIS sync
        processed_in_this_sync: Dict[str, EpgChannel] = {}

        # Get existing channels for this source
        existing = {ec.channel_id: ec for ec in EpgChannel.query.filter_by(source_id=source.id).all()}

        # Now update the database with collected channel data
        for channel_id, channel_data in channel_data_map.items():
            prog_stats = channel_program_stats.get(channel_id, {"count": 0, "first_time": None, "last_time": None})
            program_count = prog_stats["count"]
            first_program = prog_stats["first_time"]
            last_program = prog_stats["last_time"]

            if channel_id in existing:
                # Update existing channel from database
                ec = existing[channel_id]
                ec.display_name = channel_data["display_name"]
                ec.display_names_json = json.dumps(channel_data["display_names"])
                ec.icon_url = channel_data.get("icon_url")
                ec.url = channel_data.get("url")
                ec.program_count = program_count
                ec.first_program = first_program
                ec.last_program = last_program
                ec.last_seen = now
                ec.updated_at = now
                stats["channels_updated"] += 1
            else:
                # Create new channel
                ec = EpgChannel(
                    source_id=source.id,
                    channel_id=channel_id,
                    display_name=channel_data["display_name"],
                    display_names_json=json.dumps(channel_data["display_names"]),
                    icon_url=channel_data.get("icon_url"),
                    url=channel_data.get("url"),
                    program_count=program_count,
                    first_program=first_program,
                    last_program=last_program,
                    last_seen=now,
                )
                db.session.add(ec)
                processed_in_this_sync[channel_id] = ec
                stats["channels_added"] += 1

        # Mark channels not seen as removed (but don't delete - they may come back)
        for channel_id, ec in existing.items():
            if channel_id not in seen_channel_ids:
                stats["channels_removed"] += 1

        # Update source stats
        source.last_sync = now
        source.last_sync_status = "success"
        source.last_sync_message = f"Synced {len(seen_channel_ids)} channels, {stats['total_programs']} programs"
        source.channel_count = len(seen_channel_ids)
        source.updated_at = now

        db.session.commit()

        logger.info(
            f"EPG sync for source {source.id} ({source.name}): "
            f"added={stats['channels_added']}, updated={stats['channels_updated']}, "
            f"programs={stats['total_programs']}"
        )

        return stats

    @staticmethod
    def _parse_xmltv_time(time_str: str) -> Optional[datetime]:
        """Parse XMLTV datetime format (YYYYMMDDHHmmss +ZZZZ)"""
        if not time_str:
            return None

        # Remove timezone for basic parsing (just need date range)
        time_str = time_str.split()[0]  # Remove timezone offset
        try:
            return datetime.strptime(time_str, "%Y%m%d%H%M%S")
        except ValueError:
            try:
                return datetime.strptime(time_str, "%Y%m%d%H%M")
            except ValueError:
                return None

    @staticmethod
    def _build_callsign_epg_index(epg_channels: List[EpgChannel]) -> Dict[str, EpgChannel]:
        """
        Build an index of EPG channels by callsign for tag-based matching.

        Extracts callsigns from EPG channel IDs (e.g., "WCTI-DT.us_locals1" -> "WCTI")
        and strips common suffixes (-DT, -TV, -HD, -LD, etc.) to match against callsign tags.

        Args:
            epg_channels: List of EPG channels to index

        Returns:
            Dict mapping uppercase callsigns to EPG channels
        """
        epg_by_callsign: Dict[str, EpgChannel] = {}

        for ec in epg_channels:
            # Extract callsign from channel_id
            callsign = extract_callsign_from_xmltv_id(ec.channel_id)
            if callsign:
                callsign_upper = callsign.upper()
                # Only index if it looks like a broadcast callsign (starts with K or W)
                if len(callsign_upper) >= 3 and callsign_upper[0] in ("K", "W"):
                    # Store the full callsign
                    epg_by_callsign[callsign_upper] = ec

                    # Also store base callsign without common suffixes (-DT, -TV, -HD, -LD, -CD, -LP, etc.)
                    base_callsign = re.sub(
                        r"-(DT|TV|HD|LD|CD|LP|FM|DT2?|TV2?|LD2?)$", "", callsign_upper, flags=re.IGNORECASE
                    )
                    if base_callsign != callsign_upper and len(base_callsign) >= 3:
                        # Only add base if not already present (prefer exact match)
                        if base_callsign not in epg_by_callsign:
                            epg_by_callsign[base_callsign] = ec

        return epg_by_callsign

    @staticmethod
    def _lookup_fcc_callsign(
        channel_name: str,
        channel_tags: Set[str],
        network_tags: Set[str],
    ) -> Optional[str]:
        """
        Look up a callsign from FCC data using channel info.

        Uses city/location tags, network tags, and channel number extracted from name
        to find matching FCC facility records. Also tries to extract city names
        and callsigns from the channel name itself.

        Args:
            channel_name: The cleaned channel name (e.g., "ABC 10 ALBANY" or "ABC 3 WSIL")
            channel_tags: All tags for this channel (uppercase)
            network_tags: Tags that are known broadcast networks (e.g., ABC, NBC)

        Returns:
            Callsign string if found, None otherwise
        """
        # Extract channel numbers from name (look for standalone numbers or compound like "33/40")
        # This handles cases like "ABC 33/40 HD [BIRMINGHAM]" where we try both 33 and 40
        channel_numbers: List[int] = []

        # First, look for compound channel numbers like "33/40"
        compound_match = re.search(r"\b(\d{1,2})/(\d{1,2})\b", channel_name)
        if compound_match:
            channel_numbers.extend([int(compound_match.group(1)), int(compound_match.group(2))])
            logger.debug(f"FCC lookup: Extracted compound channel numbers: {channel_numbers}")
        else:
            # Look for standalone channel number
            channel_num_match = re.search(r"\b(\d{1,2})\b", channel_name)
            if channel_num_match:
                channel_numbers.append(int(channel_num_match.group(1)))

        # Get network from tags
        network = next(iter(network_tags), None) if network_tags else None

        # Try to find location in tags (non-network, non-quality tags that could be city names)
        # Filter out known non-location tags
        quality_tags = {"HD", "SD", "4K", "UHD", "FHD", "RAW", "60FPS", "30FPS", "HEVC", "H264", "H265"}
        country_tags = {"US", "USA", "UK", "CA", "AU", "DE", "FR", "ES", "IT", "MX", "BR", "JP"}
        network_set = {"ABC", "NBC", "CBS", "FOX", "PBS", "CW", "ION", "MY", "ME", "MYTV", "METV"}
        # US state abbreviations to filter out as separate location tags
        state_abbrevs = {
            "AL",
            "AK",
            "AZ",
            "AR",
            "CA",
            "CO",
            "CT",
            "DE",
            "FL",
            "GA",
            "HI",
            "ID",
            "IL",
            "IN",
            "IA",
            "KS",
            "KY",
            "LA",
            "ME",
            "MD",
            "MA",
            "MI",
            "MN",
            "MS",
            "MO",
            "MT",
            "NE",
            "NV",
            "NH",
            "NJ",
            "NM",
            "NY",
            "NC",
            "ND",
            "OH",
            "OK",
            "OR",
            "PA",
            "RI",
            "SC",
            "SD",
            "TN",
            "TX",
            "UT",
            "VT",
            "VA",
            "WA",
            "WV",
            "WI",
            "WY",
            "DC",
        }

        potential_locations = channel_tags - quality_tags - country_tags - network_set
        # Also filter out numeric-only tags, very short tags, and standalone state codes
        potential_locations = {
            t for t in potential_locations if len(t) >= 3 and not t.isdigit() and t not in state_abbrevs
        }

        # Extract DMA tags (format: DMA:MARKET_NAME or just the market name)
        dma_locations: Set[str] = set()
        for tag in channel_tags:
            if tag.startswith("DMA:"):
                # Extract DMA name and process it
                dma_name = tag[4:]  # Remove "DMA:" prefix
                # Convert underscores to spaces and also remove common DMA suffixes
                dma_name = dma_name.replace("_", " ").replace(" AND ", "-").replace(" ANN ", "-")
                dma_locations.add(dma_name)
                logger.debug(f"FCC lookup: Extracted DMA tag: {dma_name}")

        # Convert underscores to spaces in location tags (tags like "LAS_VEGAS" → "LAS VEGAS")
        # This is needed because tags often store multi-word locations with underscores
        # Also handle state suffixes (e.g., "MERIDIAN_MS" → "MERIDIAN" and "BINGHAMPTON_NY" → "BINGHAMPTON")
        processed_locations: Set[str] = set()
        for loc in potential_locations:
            # Replace underscores with spaces
            loc_spaced = loc.replace("_", " ")
            processed_locations.add(loc_spaced)

            # If location ends with a state code (e.g., "MERIDIAN MS"), also add just the city
            parts = loc_spaced.split()
            if len(parts) >= 2 and parts[-1] in state_abbrevs:
                city_only = " ".join(parts[:-1])
                processed_locations.add(city_only)
                logger.debug(f"FCC lookup: Extracted city from location tag: {city_only} (from {loc})")

        potential_locations = processed_locations

        # For multi-word locations (e.g., "HAMPTON ROADS", "LAS VEGAS"), also try:
        # 1. Individual words (for cases like "HAMPTON ROADS" where city is just "HAMPTON")
        # 2. The full phrase (for cases like "LAS VEGAS" where city is "LAS VEGAS")
        expanded_locations: Set[str] = set()
        for loc in potential_locations:
            expanded_locations.add(loc)  # Add the full location
            words = loc.split()
            if len(words) > 1:
                # Add individual words that are long enough to be city names
                for word in words:
                    if len(word) >= 4:  # Skip short words like "OF", "THE", etc.
                        expanded_locations.add(word)
        potential_locations = expanded_locations

        # Try to extract callsign from channel name (e.g., "ABC 3 WSIL" -> "WSIL")
        # US broadcast callsigns are 3-4 letters starting with K (west) or W (east)
        potential_callsigns: Set[str] = set()
        callsign_pattern = re.compile(r"\b([KW][A-Z]{2,3}(?:-[A-Z]{2,3})?)\b", re.IGNORECASE)
        if channel_name:
            matches = callsign_pattern.findall(channel_name.upper())
            for match in matches:
                # Filter out network names that look like callsigns
                if match not in network_set and len(match) >= 3:
                    potential_callsigns.add(match)
                    logger.debug(f"FCC lookup: Extracted potential callsign from name: {match}")

        # Also check tags for callsign-like patterns (e.g., WMAR, KABC)
        for tag in channel_tags:
            if callsign_pattern.match(tag) and tag not in network_set:
                potential_callsigns.add(tag)

        # If no location tags found, try to extract city name from channel name
        # Look for words at the end of the name that could be city names
        # e.g., "ABC 13 Asheville" -> "Asheville"
        if not potential_locations and channel_name:
            # Remove network and numbers from name to isolate potential city
            name_for_city = channel_name.upper()
            # Remove network names
            for net in network_set:
                name_for_city = re.sub(rf"\b{net}\b", "", name_for_city)
            # Remove numbers
            name_for_city = re.sub(r"\b\d+\b", "", name_for_city)
            # Remove quality tags
            for qt in quality_tags:
                name_for_city = re.sub(rf"\b{qt}\b", "", name_for_city)
            # Remove potential callsigns (we handle those separately)
            for cs in potential_callsigns:
                name_for_city = re.sub(rf"\b{re.escape(cs)}\b", "", name_for_city)
            # Split on slashes and hyphens to handle multi-city names like "GREENSBORO/HIGH POINT/WINSTON-SALEM"
            name_for_city = name_for_city.replace("/", " ").replace("-", " ")
            # Clean up and get remaining words
            remaining_words = [w.strip() for w in name_for_city.split() if len(w.strip()) >= 3]
            if remaining_words:
                # Add these as potential locations to try
                potential_locations = set(remaining_words)
                logger.debug(f"FCC lookup: Extracted potential cities from name: {potential_locations}")

        # Helper function to try FCC lookup with given parameters
        # This uses FccFacilityService to apply corrections before filtering
        def try_fcc_lookup(
            location: Optional[str],
            with_channel: bool,
            use_dma: bool = False,
            allow_independent: bool = False,
            channel_num: Optional[int] = None,
        ) -> Optional[str]:
            from services.fcc_facility_service import FccFacilityService

            if location:
                if use_dma:
                    # Search by Nielsen DMA (Designated Market Area) instead of city
                    query = FccFacility.query.filter(FccFacility.nielsen_dma.ilike(f"%{location}%"))
                else:
                    # Search by community_city (the city where the station is licensed)
                    query = FccFacility.query.filter(FccFacility.community_city.ilike(f"%{location}%"))
            else:
                # No location filter - used for callsign-only searches
                query = FccFacility.query

            if with_channel and channel_num is not None:
                # Match by virtual channel (what viewers see) preferentially
                query = query.filter(
                    db.or_(
                        FccFacility.tv_virtual_channel == str(channel_num),
                        FccFacility.channel == str(channel_num),
                    )
                )

            # Get all facilities matching location/channel criteria and apply corrections
            facilities = FccFacilityService.query_with_corrections(query)

            # Now filter by network affiliation (after corrections are applied)
            if allow_independent:
                # Accept INDEPENDENT or blank network affiliation
                facilities = [
                    f
                    for f in facilities
                    if not f.network_affiliation or f.network_affiliation.upper() in ("", "INDEPENDENT")
                ]
            elif network:
                # Filter by network (case-insensitive contains)
                # Also check if the callsign contains the network name (e.g., WCWG for CW)
                network_upper = network.upper()
                facilities = [
                    f
                    for f in facilities
                    if (f.network_affiliation and network_upper in f.network_affiliation.upper())
                    or (f.callsign and network_upper in f.callsign.upper())
                ]

            if len(facilities) == 1:
                return facilities[0].callsign
            elif len(facilities) > 1:
                # Multiple matches - if all have same callsign, use it
                callsigns = {f.callsign for f in facilities}
                if len(callsigns) == 1:
                    return callsigns.pop()
            return None

        # Strategy 1: Try to match by callsign extracted from name/tags first
        # This is the most reliable method when a callsign is present
        from services.fcc_facility_service import FccFacilityService

        for callsign in potential_callsigns:
            # Check if this callsign exists in FCC data (with corrections applied)
            query = FccFacility.query.filter(FccFacility.callsign.ilike(f"{callsign}%"))
            facility = FccFacilityService.first_with_correction(query)
            if facility:
                logger.debug(f"FCC lookup: Direct callsign match for {callsign}: {facility.callsign}")
                return facility.callsign

        # Strategy 2: Try each potential location with network + channel number
        for location in potential_locations:
            # First try with channel number for precision (if we have any)
            # For compound channels like "33/40", try each number independently
            for ch_num in channel_numbers:
                result = try_fcc_lookup(location, with_channel=True, channel_num=ch_num)
                if result:
                    logger.debug(
                        f"FCC lookup: Found match for location={location}, "
                        f"network={network}, channel={ch_num}: {result}"
                    )
                    return result

            # Fall back to matching by location + network without channel number
            # This is useful because IPTV channel numbers often don't match FCC RF channels
            if network:
                result = try_fcc_lookup(location, with_channel=False)
                if result:
                    logger.debug(
                        f"FCC lookup: Found match for location={location}, "
                        f"network={network} (no channel filter): {result}"
                    )
                    return result

        # Strategy 3: Try searching by Nielsen DMA (Designated Market Area)
        # This handles cases like Raleigh where the ABC affiliate (WTVD) is licensed to Durham
        # but serves the "Raleigh-Durham" DMA
        if network:
            # First try explicit DMA tags
            for dma in dma_locations:
                result = try_fcc_lookup(dma, with_channel=False, use_dma=True)
                if result:
                    logger.debug(f"FCC lookup: Found match via DMA tag for dma={dma}, " f"network={network}: {result}")
                    return result

            # Then try potential locations as DMA searches
            for location in potential_locations:
                result = try_fcc_lookup(location, with_channel=False, use_dma=True)
                if result:
                    logger.debug(
                        f"FCC lookup: Found match via DMA for location={location}, " f"network={network}: {result}"
                    )
                    return result

        # Strategy 4: If no network match found, try INDEPENDENT/blank affiliations
        # when we have a channel number match (for stations with missing affiliation data)
        if channel_numbers and potential_locations:
            for location in potential_locations:
                for ch_num in channel_numbers:
                    result = try_fcc_lookup(location, with_channel=True, allow_independent=True, channel_num=ch_num)
                    if result:
                        logger.debug(
                            f"FCC lookup: Found independent station for location={location}, "
                            f"channel={ch_num}: {result}"
                        )
                        return result

        return None

    @staticmethod
    def match_channels_to_epg(
        account_id: int,
        source_id: Optional[int] = None,
        category_id: Optional[int] = None,
        skip_matched_threshold: float = 0.85,
        batch_size: int = 50,
        include_filtered: bool = False,
    ) -> Dict:
        """
        Attempt to match channels from an account to EPG channels.

        Matching strategies:
        1. Exact match on epg_channel_id (provider-assigned)
        2. Callsign tag match (matches channel's callsign tags to EPG channel IDs)
        3. FCC lookup (uses city, network, channel number to find callsign)
        4. Exact match on cleaned channel name
        5. Fuzzy match on channel name

        Args:
            account_id: Account to match channels for
            source_id: Optional - limit to specific EPG source
            category_id: Optional - limit to channels in specific category
            skip_matched_threshold: Skip channels with existing match at or above
                                    this confidence (default 0.85)
            batch_size: Number of channels to process before committing (default 50).
                       Smaller batches reduce memory usage and provide more frequent
                       progress updates for long-running operations.
            include_filtered: Include filtered out (is_visible=False) channels (default False).
                            By default, only visible channels are matched.

        Returns:
            Dict with matching statistics

        Note:
            For accounts with thousands of channels, this operation may take several
            minutes. The process commits in batches to prevent data loss if interrupted.
        """
        stats = {
            "total_channels": 0,
            "skipped_existing": 0,
            "skipped_ppv": 0,
            "matched_exact_id": 0,
            "matched_callsign_tag": 0,
            "matched_callsign_name": 0,
            "matched_fcc_lookup": 0,
            "matched_exact_name": 0,
            "matched_fuzzy": 0,
            "matched_network_fallback": 0,
            "unmatched": 0,
        }

        # Get channels for this account, optionally filtered by category
        # By default, only match visible (non-filtered) channels
        query = Channel.query.filter_by(account_id=account_id, is_active=True)
        if not include_filtered:
            query = query.filter_by(is_visible=True)
        if category_id:
            query = query.filter_by(category_id=category_id)
        channels = query.all()

        stats["total_channels"] = len(channels)
        filter_desc = ""
        if category_id:
            filter_desc = f" in category {category_id}"
        visibility_desc = " (visible only)" if not include_filtered else " (including filtered)"
        logger.info(
            f"EPG matching: Found {len(channels)} active channels{filter_desc}{visibility_desc} for account {account_id}"
        )

        # Get all EPG channels
        epg_query = EpgChannel.query
        if source_id:
            epg_query = epg_query.filter_by(source_id=source_id)
        epg_channels = epg_query.all()
        logger.info(
            f"EPG matching: Found {len(epg_channels)} EPG channels{f' for source {source_id}' if source_id else ''}"
        )

        # Build lookup indices
        epg_by_id = {ec.channel_id.lower(): ec for ec in epg_channels}
        logger.debug(f"EPG matching: Built index with {len(epg_by_id)} unique EPG channel IDs")
        epg_by_name = {}
        for ec in epg_channels:
            # Index by all display names
            names = [ec.display_name.lower()] if ec.display_name else []
            if ec.display_names_json:
                try:
                    names.extend([n.lower() for n in json.loads(ec.display_names_json)])
                except (json.JSONDecodeError, TypeError):
                    pass
            for name in names:
                normalized = EpgService._normalize_name(name)
                if normalized:
                    epg_by_name[normalized] = ec

        # Build callsign index for EPG channels (maps callsigns like "WCTI" to EPG channels)
        epg_by_callsign = EpgService._build_callsign_epg_index(epg_channels)
        logger.debug(f"EPG matching: Built callsign index with {len(epg_by_callsign)} entries")

        # Get existing mappings to avoid duplicates
        # Batch the query to avoid SQLite's "too many SQL variables" error
        # SQLite has a limit (typically 999 or 32766) on bind parameters
        BATCH_SIZE = 500
        existing_mappings: Dict[int, ChannelEpgMapping] = {}
        channel_ids = [c.id for c in channels]
        for i in range(0, len(channel_ids), BATCH_SIZE):
            batch = channel_ids[i : i + BATCH_SIZE]
            for m in ChannelEpgMapping.query.filter(ChannelEpgMapping.channel_id.in_(batch)).all():
                existing_mappings[m.channel_id] = m

        # Pre-load ALL tags for all channels in batches for efficiency
        # This includes country tags for filtering and callsign tags for matching
        stream_ids = [c.stream_id for c in channels]
        all_tags_by_stream: Dict[str, Set[str]] = {}
        country_tags_by_stream: Dict[str, Set[str]] = {}
        callsign_tags_by_stream: Dict[str, Set[str]] = {}

        # Get country suffix mappings for country tag detection
        country_suffix_map = EpgMatchRulesService.get_country_suffix_mappings()

        for i in range(0, len(stream_ids), BATCH_SIZE):
            batch = stream_ids[i : i + BATCH_SIZE]
            tag_rows = (
                db.session.query(ChannelTag.stream_id, Tag.name)
                .join(Tag, Tag.id == ChannelTag.tag_id)
                .filter(ChannelTag.account_id == account_id, ChannelTag.stream_id.in_(batch))
                .all()
            )
            for stream_id, tag_name in tag_rows:
                tag_upper = tag_name.upper()

                # Store all tags
                if stream_id not in all_tags_by_stream:
                    all_tags_by_stream[stream_id] = set()
                all_tags_by_stream[stream_id].add(tag_upper)

                # Track country tags separately
                if tag_upper in country_suffix_map:
                    if stream_id not in country_tags_by_stream:
                        country_tags_by_stream[stream_id] = set()
                    country_tags_by_stream[stream_id].add(tag_upper)

                # Track callsign tags (K/W prefix, 3-6 alphanumeric chars)
                if len(tag_upper) >= 3 and len(tag_upper) <= 6 and tag_upper[0] in ("K", "W") and tag_upper.isalnum():
                    if stream_id not in callsign_tags_by_stream:
                        callsign_tags_by_stream[stream_id] = set()
                    callsign_tags_by_stream[stream_id].add(tag_upper)

        logger.debug(
            f"EPG matching: Loaded tags for {len(all_tags_by_stream)} channels, "
            f"{len(callsign_tags_by_stream)} with callsign tags"
        )

        # Process channels in batches for better performance and incremental saves
        channels_processed = 0

        for channel in channels:
            logger.debug(f"EPG matching: Processing channel '{channel.name}' (stream_id={channel.stream_id})")

            # Skip PPV channels - they update dynamically and don't have traditional EPG
            # Use pre-computed is_ppv column instead of expensive pattern matching
            if channel.is_ppv:
                stats["skipped_ppv"] += 1
                logger.debug(
                    f"  -> Skipping PPV channel (category='{channel.category.category_name if channel.category else 'None'}')"
                )
                continue

            # Skip if already has a manual override mapping
            if channel.id in existing_mappings:
                existing = existing_mappings[channel.id]
                if existing.is_override:
                    stats["skipped_existing"] += 1
                    logger.debug("  -> Skipping (has manual override mapping)")
                    continue
                # Skip if existing match is good enough
                if existing.confidence and existing.confidence >= skip_matched_threshold:
                    stats["skipped_existing"] += 1
                    logger.debug(
                        f"  -> Skipping (existing match confidence {existing.confidence:.2f} >= {skip_matched_threshold})"
                    )
                    continue

            matched_epg = None
            match_type = None
            confidence = 0.0

            # Get country tags for this channel
            channel_country_tags = country_tags_by_stream.get(channel.stream_id, set())

            # Strategy 1: Exact match on epg_channel_id from provider
            # Skip obviously bad/placeholder EPG IDs (too short or generic)
            if channel.epg_channel_id and len(channel.epg_channel_id) > 3:
                logger.debug(f"  Strategy 1: Checking provider EPG ID '{channel.epg_channel_id}'")
                epg_id_lower = channel.epg_channel_id.lower()
                if epg_id_lower in epg_by_id:
                    matched_epg = epg_by_id[epg_id_lower]
                    match_type = "provider"
                    confidence = 1.0
                    stats["matched_exact_id"] += 1
                    logger.info(f"  ✓ Matched via provider EPG ID: '{channel.name}' -> '{matched_epg.display_name}'")

            # Strategy 2: Callsign tag match (for US broadcast stations)
            # Match channel's callsign tags (e.g., "WCTI") to EPG channel IDs (e.g., "WCTI-DT.us")
            if not matched_epg and "US" in channel_country_tags:
                channel_callsign_tags = callsign_tags_by_stream.get(channel.stream_id, set())
                if channel_callsign_tags:
                    logger.debug(f"  Strategy 2: Checking callsign tags: {channel_callsign_tags}")
                for callsign_tag in channel_callsign_tags:
                    if callsign_tag in epg_by_callsign:
                        matched_epg = epg_by_callsign[callsign_tag]
                        match_type = "callsign_tag"
                        confidence = 0.97  # High confidence for callsign match
                        stats["matched_callsign_tag"] += 1
                        logger.info(
                            f"  ✓ Matched via callsign tag: '{channel.name}' -> "
                            f"'{matched_epg.display_name}' (tag={callsign_tag}, confidence={confidence:.2f})"
                        )
                        break

            # Strategy 3: FCC lookup (for US broadcast stations without callsign tag)
            # Use city/location tags, network tags, and channel number to find callsign in FCC data
            if not matched_epg and "US" in channel_country_tags:
                channel_all_tags = all_tags_by_stream.get(channel.stream_id, set())
                # Find network tags for this channel
                channel_network_tags = channel_all_tags & MAJOR_BROADCAST_NETWORKS
                if channel_network_tags:
                    logger.debug(f"  Strategy 3: FCC lookup with networks={channel_network_tags}")
                    # Try FCC lookup
                    fcc_callsign = EpgService._lookup_fcc_callsign(
                        channel.cleaned_name or channel.name,
                        channel_all_tags,
                        channel_network_tags,
                    )
                    if fcc_callsign:
                        logger.debug(f"    Found FCC callsign: {fcc_callsign}")
                        fcc_upper = fcc_callsign.upper()
                        # Try exact FCC callsign first
                        if fcc_upper in epg_by_callsign:
                            matched_epg = epg_by_callsign[fcc_upper]
                        else:
                            # Strip suffix (-TV, -DT, -LD, etc.) and try base callsign
                            # FCC uses -TV suffix, EPG often uses -DT or -LD
                            base_callsign = re.sub(
                                r"-(DT|TV|HD|LD|CD|LP|FM|DT2?|TV2?|LD2?)$", "", fcc_upper, flags=re.IGNORECASE
                            )
                            if base_callsign in epg_by_callsign:
                                matched_epg = epg_by_callsign[base_callsign]

                        if matched_epg:
                            match_type = "fcc_lookup"
                            confidence = 0.93  # High confidence but slightly less than direct callsign tag
                            stats["matched_fcc_lookup"] += 1
                            logger.info(
                                f"  ✓ Matched via FCC lookup: '{channel.name}' -> "
                                f"'{matched_epg.display_name}' (callsign={fcc_callsign}, confidence={confidence:.2f})"
                            )

            # Strategy 4: Callsign extracted from channel name (for US broadcast stations)
            # Extract callsign from channel name (e.g., "US: CBS 13 (WSVF-CD2)" -> "WSVF")
            # and match to EPG channels with the same base callsign
            # This is after FCC lookup since it's less authoritative - useful for stations
            # not in FCC database or EPG sources like us_locals1 with minimal metadata
            if not matched_epg and "US" in channel_country_tags:
                from services.fcc_facility_service import FccFacilityService

                logger.debug("  Strategy 4: Extracting callsign from name")
                extracted_callsign = FccFacilityService.extract_callsign_from_name(channel.name)
                if extracted_callsign:
                    logger.debug(f"    Extracted callsign: {extracted_callsign}")
                    extracted_upper = extracted_callsign.upper()
                    if extracted_upper in epg_by_callsign:
                        matched_epg = epg_by_callsign[extracted_upper]
                        match_type = "callsign_name"
                        confidence = 0.92  # Slightly lower than FCC lookup
                        stats["matched_callsign_name"] += 1
                        logger.info(
                            f"  ✓ Matched via callsign from name: '{channel.name}' -> "
                            f"'{matched_epg.display_name}' (callsign={extracted_callsign}, confidence={confidence:.2f})"
                        )

            # Strategy 5: Exact match on cleaned name
            if not matched_epg and channel.cleaned_name:
                normalized = EpgService._normalize_name(channel.cleaned_name)
                logger.debug(f"  Strategy 5: Checking exact name match (normalized='{normalized}')")
                if normalized and normalized in epg_by_name:
                    matched_epg = epg_by_name[normalized]
                    match_type = "auto_exact"
                    confidence = 0.95
                    stats["matched_exact_name"] += 1
                    logger.info(
                        f"  ✓ Matched via exact name: '{channel.name}' -> '{matched_epg.display_name}' (confidence={confidence:.2f})"
                    )

            # Strategy 6: Fuzzy match (includes token matching, contains, country filtering, etc.)
            if not matched_epg:
                logger.info(
                    f"  Strategy 6: Starting fuzzy search for '{channel.name}' (cleaned: '{channel.cleaned_name or channel.name}')"
                )
                best_match, best_score = EpgService._fuzzy_match(
                    channel.cleaned_name or channel.name,
                    epg_channels,
                    country_tags=channel_country_tags if channel_country_tags else None,
                )
                if best_match and best_score >= 0.75:
                    matched_epg = best_match
                    match_type = "auto_fuzzy"
                    confidence = best_score
                    stats["matched_fuzzy"] += 1
                    logger.info(
                        f"  ✓ Matched via fuzzy match: '{channel.name}' -> '{matched_epg.display_name}' (confidence={confidence:.2f})"
                    )
                else:
                    logger.info(
                        f"  ✗ No fuzzy match found for '{channel.name}'"
                        + (f" (best_score={best_score:.2f} < 0.75)" if best_match else "")
                    )

            # Strategy 7: Network fallback (for US broadcast stations with no local EPG)
            # Fall back to generic network feed when no local station EPG data exists
            # Uses lower confidence (< 0.80) to indicate this is a fallback match
            if not matched_epg and "US" in channel_country_tags:
                channel_all_tags = all_tags_by_stream.get(channel.stream_id, set())
                channel_network_tags = channel_all_tags & MAJOR_BROADCAST_NETWORKS
                for network in channel_network_tags:
                    if network in NETWORK_FALLBACK_EPG_IDS:
                        fallback_options = NETWORK_FALLBACK_EPG_IDS[network]
                        for fallback_id, fallback_name in fallback_options:
                            fallback_lower = fallback_id.lower()
                            if fallback_lower in epg_by_id:
                                matched_epg = epg_by_id[fallback_lower]
                                match_type = "network_fallback"
                                confidence = 0.75  # Below 0.80 to indicate fallback
                                stats["matched_network_fallback"] += 1
                                logger.info(
                                    f"EPG fallback to generic network: '{channel.name}' -> "
                                    f"'{matched_epg.display_name}' (network={network}, no local EPG available)"
                                )
                                break
                    if matched_epg:
                        break

            if matched_epg and match_type:
                # Create or update mapping
                if channel.id in existing_mappings:
                    mapping = existing_mappings[channel.id]
                    if not mapping.is_override:  # Don't overwrite manual mappings
                        mapping.epg_channel_id = matched_epg.id
                        mapping.mapping_type = match_type
                        mapping.confidence = confidence
                        mapping.updated_at = datetime.utcnow()
                        logger.debug("  Updated existing mapping")
                else:
                    mapping = ChannelEpgMapping(
                        channel_id=channel.id,
                        epg_channel_id=matched_epg.id,
                        mapping_type=match_type,
                        confidence=confidence,
                    )
                    db.session.add(mapping)
                    logger.debug("  Created new mapping")
            else:
                stats["unmatched"] += 1
                logger.debug(f"  ✗ No match found for '{channel.name}'")

            # Commit in batches and flush session to prevent memory buildup
            channels_processed += 1
            if channels_processed % batch_size == 0:
                db.session.commit()
                db.session.flush()  # Clear session cache to prevent memory issues
                elapsed_pct = (channels_processed / len(channels)) * 100
                matched_so_far = sum(
                    [
                        stats["matched_exact_id"],
                        stats["matched_callsign_tag"],
                        stats["matched_callsign_name"],
                        stats["matched_fcc_lookup"],
                        stats["matched_exact_name"],
                        stats["matched_fuzzy"],
                        stats["matched_network_fallback"],
                    ]
                )
                logger.info(
                    f"EPG matching progress: {channels_processed}/{len(channels)} channels "
                    f"({elapsed_pct:.1f}%) - {matched_so_far} matched, {stats['unmatched']} unmatched, "
                    f"{stats['skipped_existing']} skipped, {stats['skipped_ppv']} PPV"
                )

        # Final commit for any remaining
        db.session.commit()

        logger.info(
            f"EPG matching for account {account_id}{filter_desc}: "
            f"skipped_existing={stats['skipped_existing']}, skipped_ppv={stats['skipped_ppv']}, "
            f"exact_id={stats['matched_exact_id']}, "
            f"callsign_tag={stats['matched_callsign_tag']}, callsign_name={stats['matched_callsign_name']}, "
            f"fcc_lookup={stats['matched_fcc_lookup']}, "
            f"exact_name={stats['matched_exact_name']}, fuzzy={stats['matched_fuzzy']}, "
            f"network_fallback={stats['matched_network_fallback']}, "
            f"unmatched={stats['unmatched']}"
        )

        return stats

    @staticmethod
    def _normalize_name(name: str) -> str:
        """Normalize a channel name for matching"""
        if not name:
            return ""
        # Lowercase, keep only ASCII alphanumeric and spaces, collapse whitespace
        name = name.lower()
        # Only keep a-z, 0-9, and spaces (removes all Unicode special chars)
        name = re.sub(r"[^a-z0-9\s]", "", name)
        name = re.sub(r"\s+", " ", name).strip()
        return name

    @staticmethod
    def _extract_country_from_epg_id(epg_channel_id: str) -> Optional[str]:
        """
        Extract country code from EPG channel ID.

        Common patterns:
        - "ESPN.us" -> "US"
        - "Court.TV.us2" -> "US"
        - "BBC1.uk" -> "UK"
        - "RTL.de" -> "DE"

        Returns:
            Uppercase country code or None
        """
        if not epg_channel_id:
            return None

        channel_id_lower = epg_channel_id.lower()

        # Check for known country suffixes from database
        country_suffix_map = EpgMatchRulesService.get_country_suffix_mappings()
        for country_tag, suffixes in country_suffix_map.items():
            for suffix in suffixes:
                if channel_id_lower.endswith(suffix):
                    return country_tag

        # Try to extract 2-letter suffix after last dot
        if "." in epg_channel_id:
            last_part = epg_channel_id.split(".")[-1].lower()
            # Remove trailing numbers (e.g., "us2" -> "us")
            country_part = re.sub(r"\d+$", "", last_part)
            if len(country_part) == 2 and country_part.isalpha():
                return country_part.upper()

        return None

    @staticmethod
    def _get_channel_country_tags(account_id: int, stream_id: str) -> Set[str]:
        """
        Get country-related tags for a channel.

        Returns:
            Set of uppercase country codes found in channel's tags
        """
        # Query tags for this channel
        tag_names = (
            db.session.query(Tag.name)
            .join(ChannelTag, Tag.id == ChannelTag.tag_id)
            .filter(ChannelTag.account_id == account_id, ChannelTag.stream_id == stream_id)
            .all()
        )

        # Get country suffix mappings from database
        country_suffix_map = EpgMatchRulesService.get_country_suffix_mappings()

        # Filter to just country codes
        country_codes = set()
        for (tag_name,) in tag_names:
            tag_upper = tag_name.upper()
            if tag_upper in country_suffix_map:
                country_codes.add(tag_upper)

        return country_codes

    # Common suffixes/prefixes to strip when trying variations
    # These are quality/region markers that don't affect channel identity
    STRIP_WORDS = {
        "hd",
        "sd",
        "fhd",
        "uhd",
        "4k",
        "8k",
        "the",
        "channel",
        "channels",
        "tv",
        "network",
        "networks",
        "television",
        "us",
        "uk",
        "ca",
        "au",
        "de",
        "fr",
        "es",
        "it",
        "east",
        "west",
        "pacific",
        "central",
        "plus",
        "extra",
        "max",
        "international",
        "world",
        "global",
    }

    @staticmethod
    def _get_name_tokens(name: str) -> Set[str]:
        """Extract meaningful tokens from a channel name for matching"""
        if not name:
            return set()

        normalized = EpgService._normalize_name(name)
        if not normalized:
            return set()

        # Split into words and filter out common noise words
        tokens = set(normalized.split())
        # Keep tokens that are either not noise or are the only token
        meaningful = {t for t in tokens if t not in EpgService.STRIP_WORDS or len(tokens) == 1}
        return meaningful if meaningful else tokens

    @staticmethod
    def _get_name_variations(name: str) -> List[str]:
        """
        Generate variations of a name by stripping common suffixes/prefixes.
        Returns list of variations to try, most specific first.
        """
        if not name:
            return []

        normalized = EpgService._normalize_name(name)
        if not normalized:
            return []

        variations = [normalized]
        words = normalized.split()

        if len(words) <= 1:
            return variations

        # Try stripping from the end
        for i in range(len(words) - 1, 0, -1):
            if words[i] in EpgService.STRIP_WORDS:
                stripped = " ".join(words[:i])
                if stripped and stripped not in variations:
                    variations.append(stripped)
            else:
                break

        # Try stripping from the beginning
        for i in range(len(words) - 1):
            if words[i] in EpgService.STRIP_WORDS:
                stripped = " ".join(words[i + 1 :])
                if stripped and stripped not in variations:
                    variations.append(stripped)
            else:
                break

        # Try stripping both ends
        start = 0
        end = len(words)
        for i in range(len(words)):
            if words[i] in EpgService.STRIP_WORDS:
                start = i + 1
            else:
                break
        for i in range(len(words) - 1, -1, -1):
            if words[i] in EpgService.STRIP_WORDS:
                end = i
            else:
                break
        if start < end:
            stripped = " ".join(words[start:end])
            if stripped and stripped not in variations:
                variations.append(stripped)

        return variations

    @staticmethod
    def _calculate_match_score(channel_name: str, epg_name: str) -> Tuple[float, str]:
        """
        Calculate a match score between a channel name and EPG name.

        Returns:
            Tuple of (score 0-1, match_type string)
        """
        if not channel_name or not epg_name:
            return 0.0, "none"

        norm_channel = EpgService._normalize_name(channel_name)
        norm_epg = EpgService._normalize_name(epg_name)

        if not norm_channel or not norm_epg:
            return 0.0, "none"

        # Minimum length requirements to avoid spurious matches
        # Very short names like "A+", "E!" should only match exactly
        MIN_NAME_LENGTH = 3
        if len(norm_epg) < MIN_NAME_LENGTH or len(norm_channel) < MIN_NAME_LENGTH:
            if norm_channel == norm_epg:
                return 1.0, "exact"
            return 0.0, "none"

        # Strategy 1: Exact match after normalization
        if norm_channel == norm_epg:
            return 1.0, "exact"

        # Strategy 2: Try variations with stripped suffixes/prefixes for exact match
        channel_variations = EpgService._get_name_variations(channel_name)
        epg_variations = EpgService._get_name_variations(epg_name)

        for cv in channel_variations:
            for ev in epg_variations:
                if cv == ev and len(cv) >= MIN_NAME_LENGTH:
                    # Exact match after stripping - high confidence
                    return 0.95, "exact_stripped"

        # Strategy 3: Check for common abbreviation patterns
        # E.g., "BBC" should match "British Broadcasting Corporation"
        if len(norm_channel) <= 5 and len(norm_channel) >= 2 and norm_channel.isalpha():
            epg_words = norm_epg.split()
            if len(epg_words) >= len(norm_channel):
                initials = "".join(w[0] for w in epg_words[: len(norm_channel)])
                if initials == norm_channel:
                    return 0.90, "abbreviation"

        # Also check reverse: EPG is abbreviation of channel name
        if len(norm_epg) <= 5 and len(norm_epg) >= 2 and norm_epg.isalpha():
            channel_words = norm_channel.split()
            if len(channel_words) >= len(norm_epg):
                initials = "".join(w[0] for w in channel_words[: len(norm_epg)])
                if initials == norm_epg:
                    return 0.90, "abbreviation"

        # Strategy 4: One contains the other - but with stricter requirements
        MIN_CONTAINS_LENGTH = 5
        if len(norm_channel) >= MIN_CONTAINS_LENGTH and norm_channel in norm_epg:
            ratio = len(norm_channel) / len(norm_epg)
            # Only match if we cover at least 60% of the EPG name
            if ratio >= 0.6:
                score = 0.80 + (ratio * 0.15)  # 0.80 - 0.95
                return min(score, 0.95), "contains"

        if len(norm_epg) >= MIN_CONTAINS_LENGTH and norm_epg in norm_channel:
            ratio = len(norm_epg) / len(norm_channel)
            # Only match if EPG name covers at least 60% of channel name
            if ratio >= 0.6:
                score = 0.75 + (ratio * 0.15)  # 0.75 - 0.90
                return min(score, 0.90), "contains"

        # Strategy 5: Token-based matching with stricter requirements
        channel_tokens = EpgService._get_name_tokens(channel_name)
        epg_tokens = EpgService._get_name_tokens(epg_name)

        if channel_tokens and epg_tokens and len(channel_tokens) >= 1 and len(epg_tokens) >= 1:
            shorter, longer = (
                (channel_tokens, epg_tokens) if len(channel_tokens) <= len(epg_tokens) else (epg_tokens, channel_tokens)
            )

            matching_tokens = shorter & longer

            # Require ALL tokens from shorter to match AND substantial coverage
            if matching_tokens == shorter and len(shorter) >= 2:
                coverage = len(shorter) / len(longer)
                if coverage >= 0.5:
                    score = 0.80 + (coverage * 0.15)  # 0.80 - 0.95
                    return min(score, 0.95), "token_match"

            # Single meaningful token match - both names have just 1 token
            if len(matching_tokens) == 1 and len(shorter) == 1 and len(longer) == 1:
                return 0.90, "token_match"

        # Strategy 6: Fuzzy sequence matching (fallback) - stricter threshold
        # Only use fuzzy if names are similar lengths (within 2x of each other)
        length_ratio = min(len(norm_channel), len(norm_epg)) / max(len(norm_channel), len(norm_epg))
        if length_ratio < 0.5:
            # Names are too different in length - likely not a match
            return 0.0, "none"

        # Additional early exit: skip if length difference is too large (>30 chars)
        length_diff = abs(len(norm_channel) - len(norm_epg))
        if length_diff > 30:
            return 0.0, "none"

        # SequenceMatcher is expensive - only use for promising candidates
        seq_score = SequenceMatcher(None, norm_channel, norm_epg).ratio()

        # Only return fuzzy scores above a high threshold (0.85)
        # This avoids false positives from partial word matches
        if seq_score >= 0.85:
            return seq_score, "fuzzy"

        return 0.0, "none"

    @staticmethod
    def _fuzzy_match(
        channel_name: str,
        epg_channels: List[EpgChannel],
        min_score: float = 0.75,
        country_tags: Optional[Set[str]] = None,
    ) -> Tuple[Optional[EpgChannel], float]:
        """
        Find the best fuzzy match for a channel name.

        Uses multiple matching strategies:
        1. Exact match after normalization
        2. Exact match with stripped suffixes (HD, Network, etc.)
        3. Abbreviation matching
        4. Contains/prefix matching (with stricter requirements)
        5. Token-based matching (all significant words match)
        6. Fuzzy sequence matching (high threshold)
        5. Abbreviation matching
        6. Country tag matching (boost/filter by country suffix in EPG channel ID)

        Args:
            channel_name: The channel name to match
            epg_channels: List of EPG channels to search
            min_score: Minimum similarity score (0-1), default 0.65
            country_tags: Optional set of country codes (e.g., {"US", "UK"}) to prefer

        Returns:
            Tuple of (best matching EpgChannel or None, score)
        """
        if not channel_name:
            return None, 0.0

        normalized_name = EpgService._normalize_name(channel_name)
        if not normalized_name:
            return None, 0.0

        logger.info(
            f"    Fuzzy matching '{channel_name}' (normalized: '{normalized_name}') against {len(epg_channels)} EPG channels"
        )

        # Early exit: if we have country tags, filter EPG channels by country first
        # This significantly reduces the search space
        search_channels = epg_channels
        if country_tags:
            country_filtered = [
                ec
                for ec in epg_channels
                if not ec.channel_id or EpgService._extract_country_from_epg_id(ec.channel_id) in country_tags
            ]
            # If country filtering removed everything, fall back to full list
            if country_filtered:
                search_channels = country_filtered
                logger.debug(f"    Filtered to {len(search_channels)} channels matching country tags {country_tags}")

        # Track all candidates with their scores
        candidates: List[Tuple[EpgChannel, float, str, bool]] = []  # (epg, score, type, country_match)

        for ec in search_channels:
            names_to_check = [ec.display_name] if ec.display_name else []
            if ec.display_names_json:
                try:
                    names_to_check.extend(json.loads(ec.display_names_json))
                except (json.JSONDecodeError, TypeError):
                    pass

            # Check if this EPG channel's country matches our tags
            epg_country = EpgService._extract_country_from_epg_id(ec.channel_id)
            country_match = bool(country_tags and epg_country and epg_country in country_tags)

            best_name_score = 0.0
            best_name_type = "none"

            for epg_name in names_to_check:
                if not epg_name:
                    continue

                score, match_type = EpgService._calculate_match_score(channel_name, epg_name)

                if score > best_name_score:
                    best_name_score = score
                    best_name_type = match_type

                    # Early exit: if we found a perfect match, no need to check more names
                    if score >= 1.0:
                        break

            if best_name_score >= min_score:
                candidates.append((ec, best_name_score, best_name_type, country_match))

                # Early exit: if we found a perfect country-matched channel, return it immediately
                if best_name_score >= 1.0 and country_match:
                    logger.debug(f"    Found perfect match: '{ec.display_name}' (score=1.0, country_match=True)")
                    return ec, 1.0

        if not candidates:
            logger.info(f"    No candidates found with score >= {min_score}")
            return None, 0.0

        logger.info(f"    Found {len(candidates)} candidate(s) with score >= {min_score}")

        # Sort candidates: first by country match (True first), then by score descending
        candidates.sort(key=lambda x: (x[3], x[1]), reverse=True)

        best_match, best_score, best_match_type, country_matched = candidates[0]

        # Log match details
        match_info = f"    Best match: '{best_match.display_name}' "
        match_info += f"(score={best_score:.2f}, type={best_match_type}"
        if country_matched:
            match_info += ", country_match=True"
        if len(candidates) > 1:
            # Show runner-up
            runner_up = candidates[1]
            match_info += f", runner_up='{runner_up[0].display_name}' (score={runner_up[1]:.2f})"
        match_info += ")"
        logger.info(match_info)

        return best_match, best_score

    # =========================================================================
    # FCC-Enhanced EPG Matching
    # =========================================================================

    @staticmethod
    def _get_fcc_facility_for_channel(channel: Channel) -> Optional[FccFacility]:
        """
        Look up FCC facility data for a channel using its callsign.

        Extracts callsign from channel name (e.g., "US: NBC (WNBC)" -> WNBC)
        and looks up the corresponding FCC facility record.

        Args:
            channel: Channel to look up

        Returns:
            FccFacility record or None
        """
        from services.fcc_facility_service import FccFacilityService

        callsign = FccFacilityService.extract_callsign_from_name(channel.name)
        if not callsign:
            return None

        return FccFacilityService.lookup_by_callsign(callsign)

    @staticmethod
    def _match_by_fcc_callsign(
        channel: Channel,
        epg_by_callsign: Dict[str, EpgChannel],
        facility: Optional[FccFacility] = None,
    ) -> Optional[Tuple[EpgChannel, float, str]]:
        """
        Match a channel to EPG using FCC callsign data.

        EPG channels often use formats like "KABC.us" or "WNBC.us".
        This method matches using the FCC-verified callsign.

        Args:
            channel: Channel to match
            epg_by_callsign: Dict mapping callsigns to EPG channels
            facility: Optional pre-looked-up FCC facility

        Returns:
            Tuple of (EpgChannel, confidence, match_type) or None
        """
        if facility is None:
            facility = EpgService._get_fcc_facility_for_channel(channel)

        if not facility:
            return None

        # Try exact callsign match
        callsign_upper = facility.callsign.upper()
        if callsign_upper in epg_by_callsign:
            return (epg_by_callsign[callsign_upper], 0.98, "fcc_callsign")

        # Try without common suffixes (-TV, -DT, etc.)
        base_callsign = callsign_upper.split("-")[0]
        if base_callsign != callsign_upper and base_callsign in epg_by_callsign:
            return (epg_by_callsign[base_callsign], 0.95, "fcc_callsign_base")

        # Try with common suffixes added
        for suffix in ["", "TV", "DT"]:
            test_callsign = f"{base_callsign}{suffix}" if suffix else base_callsign
            if test_callsign in epg_by_callsign:
                return (epg_by_callsign[test_callsign], 0.93, "fcc_callsign_variant")

        return None

    @staticmethod
    def _match_by_fcc_network(
        channel: Channel,
        epg_by_name: Dict[str, EpgChannel],
        facility: Optional[FccFacility] = None,
    ) -> Optional[Tuple[EpgChannel, float, str]]:
        """
        Match a channel to EPG using FCC network affiliation as fallback.

        When a local station doesn't have station-specific EPG, we can
        fall back to generic network EPG (e.g., CBS affiliate -> CBS EPG).
        This is lower confidence as programming may differ.

        Args:
            channel: Channel to match
            epg_by_name: Dict mapping normalized names to EPG channels
            facility: Optional pre-looked-up FCC facility

        Returns:
            Tuple of (EpgChannel, confidence, match_type) or None
        """
        if facility is None:
            facility = EpgService._get_fcc_facility_for_channel(channel)

        if not facility or not facility.network_affiliation:
            return None

        network = facility.network_affiliation.upper()

        # Only use network fallback for major broadcast networks
        if network not in MAJOR_BROADCAST_NETWORKS:
            return None

        # Try to find network EPG channel
        network_normalized = EpgService._normalize_name(network)
        if network_normalized in epg_by_name:
            # Lower confidence since this is a fallback, not exact station match
            return (epg_by_name[network_normalized], 0.60, "fcc_network_fallback")

        return None

    @staticmethod
    def _build_fcc_epg_indices(
        epg_channels: List[EpgChannel],
    ) -> Tuple[Dict[str, EpgChannel], Dict[str, List[EpgChannel]]]:
        """
        Build lookup indices for FCC-enhanced EPG matching.

        Creates:
        1. Callsign index: Maps callsigns (extracted from EPG channel IDs) to EPG channels
        2. DMA/Market index: Maps market names to EPG channels in that market

        Args:
            epg_channels: List of EPG channels to index

        Returns:
            Tuple of (callsign_dict, dma_dict)
        """
        epg_by_callsign: Dict[str, EpgChannel] = {}
        epg_by_dma: Dict[str, List[EpgChannel]] = {}

        for ec in epg_channels:
            # Extract callsign from channel_id (e.g., "KABC.us" -> "KABC")
            callsign = extract_callsign_from_xmltv_id(ec.channel_id)
            if callsign:
                # Only index if it looks like a broadcast callsign (starts with K or W)
                callsign_upper = callsign.upper()
                if len(callsign_upper) >= 3 and callsign_upper[0] in ("K", "W"):
                    epg_by_callsign[callsign_upper] = ec

                # Also try display name as callsign
                if ec.display_name:
                    display_upper = ec.display_name.upper().strip()
                    if len(display_upper) >= 3 and len(display_upper) <= 10:
                        if display_upper[0] in ("K", "W") and display_upper.replace("-", "").isalpha():
                            epg_by_callsign[display_upper] = ec

        return epg_by_callsign, epg_by_dma

    @staticmethod
    def match_channels_to_epg_fcc_enhanced(
        account_id: int,
        source_id: Optional[int] = None,
        category_id: Optional[int] = None,
        skip_matched_threshold: float = 0.85,
        batch_size: int = 100,
        use_network_fallback: bool = True,
    ) -> Dict:
        """
        Match channels to EPG using FCC data for enhanced accuracy.

        This enhanced matcher adds FCC-based matching strategies:
        1. Exact match on provider epg_channel_id (highest priority)
        2. FCC callsign match (matches extracted callsign to EPG like "KABC.us")
        3. Exact match on cleaned channel name
        4. Fuzzy match on channel name
        5. FCC network fallback (optional - uses network EPG for unmatched affiliates)

        For US broadcast stations, this significantly improves matching accuracy
        by using authoritative FCC callsign data rather than fuzzy name matching.

        Args:
            account_id: Account to match channels for
            source_id: Optional - limit to specific EPG source
            category_id: Optional - limit to channels in specific category
            skip_matched_threshold: Skip channels with existing match at or above
                                    this confidence (default 0.85)
            batch_size: Number of channels to process before committing
            use_network_fallback: Whether to use network fallback for unmatched
                                  broadcast affiliates (default True)

        Returns:
            Dict with matching statistics including FCC-specific counts
        """
        stats = {
            "total_channels": 0,
            "skipped_existing": 0,
            "matched_exact_id": 0,
            "matched_fcc_callsign": 0,
            "matched_exact_name": 0,
            "matched_fuzzy": 0,
            "matched_network_fallback": 0,
            "unmatched": 0,
        }

        # Get channels for this account, optionally filtered by category
        query = Channel.query.filter_by(account_id=account_id, is_active=True)
        if category_id:
            query = query.filter_by(category_id=category_id)
        channels = query.all()

        stats["total_channels"] = len(channels)
        filter_desc = ""
        if category_id:
            filter_desc = f" in category {category_id}"
        logger.info(
            f"EPG matching (FCC-enhanced): Found {len(channels)} active channels{filter_desc} "
            f"for account {account_id}"
        )

        # Get all EPG channels
        epg_query = EpgChannel.query
        if source_id:
            epg_query = epg_query.filter_by(source_id=source_id)
        epg_channels = epg_query.all()
        logger.info(
            f"EPG matching: Found {len(epg_channels)} EPG channels" f"{f' for source {source_id}' if source_id else ''}"
        )

        # Build lookup indices
        epg_by_id = {ec.channel_id.lower(): ec for ec in epg_channels}
        epg_by_name: Dict[str, EpgChannel] = {}
        for ec in epg_channels:
            # Index by all display names
            names = [ec.display_name.lower()] if ec.display_name else []
            if ec.display_names_json:
                try:
                    names.extend([n.lower() for n in json.loads(ec.display_names_json)])
                except (json.JSONDecodeError, TypeError):
                    pass
            for name in names:
                normalized = EpgService._normalize_name(name)
                if normalized:
                    epg_by_name[normalized] = ec

        # Build FCC-specific indices
        epg_by_callsign, epg_by_dma = EpgService._build_fcc_epg_indices(epg_channels)
        logger.debug(f"EPG matching: Built FCC callsign index with {len(epg_by_callsign)} entries")

        # Get existing mappings to avoid duplicates
        BATCH_SIZE = 500
        existing_mappings: Dict[int, ChannelEpgMapping] = {}
        channel_ids = [c.id for c in channels]
        for i in range(0, len(channel_ids), BATCH_SIZE):
            batch = channel_ids[i : i + BATCH_SIZE]
            for m in ChannelEpgMapping.query.filter(ChannelEpgMapping.channel_id.in_(batch)).all():
                existing_mappings[m.channel_id] = m

        # Pre-load country tags for all channels in batches
        stream_ids = [c.stream_id for c in channels]
        country_tags_by_stream: Dict[str, Set[str]] = {}

        # Get country suffix mappings for country tag detection
        country_suffix_map = EpgMatchRulesService.get_country_suffix_mappings()

        for i in range(0, len(stream_ids), BATCH_SIZE):
            batch = stream_ids[i : i + BATCH_SIZE]
            tag_rows = (
                db.session.query(ChannelTag.stream_id, Tag.name)
                .join(Tag, Tag.id == ChannelTag.tag_id)
                .filter(ChannelTag.account_id == account_id, ChannelTag.stream_id.in_(batch))
                .all()
            )
            for stream_id, tag_name in tag_rows:
                tag_upper = tag_name.upper()
                if tag_upper in country_suffix_map:
                    if stream_id not in country_tags_by_stream:
                        country_tags_by_stream[stream_id] = set()
                    country_tags_by_stream[stream_id].add(tag_upper)

        # Pre-load FCC facilities for US channels (batch lookup for efficiency)
        fcc_facilities_by_channel: Dict[int, Optional[FccFacility]] = {}
        us_channel_ids = [c.id for c in channels if country_tags_by_stream.get(c.stream_id, set()) & {"US"}]
        for channel in channels:
            if channel.id in us_channel_ids:
                fcc_facilities_by_channel[channel.id] = EpgService._get_fcc_facility_for_channel(channel)
            else:
                fcc_facilities_by_channel[channel.id] = None

        logger.debug(
            f"EPG matching: Pre-loaded FCC data for {sum(1 for v in fcc_facilities_by_channel.values() if v)} channels"
        )

        channels_processed = 0

        for channel in channels:
            # Skip if already has a manual override mapping
            if channel.id in existing_mappings:
                existing = existing_mappings[channel.id]
                if existing.is_override:
                    stats["skipped_existing"] += 1
                    continue
                if existing.confidence and existing.confidence >= skip_matched_threshold:
                    stats["skipped_existing"] += 1
                    continue

            matched_epg = None
            match_type = None
            confidence = 0.0

            channel_country_tags = country_tags_by_stream.get(channel.stream_id, set())
            facility = fcc_facilities_by_channel.get(channel.id)

            # Strategy 1: Exact match on epg_channel_id from provider
            if channel.epg_channel_id and len(channel.epg_channel_id) > 3:
                epg_id_lower = channel.epg_channel_id.lower()
                if epg_id_lower in epg_by_id:
                    matched_epg = epg_by_id[epg_id_lower]
                    match_type = "provider"
                    confidence = 1.0
                    stats["matched_exact_id"] += 1

            # Strategy 2: FCC callsign match (for US channels only)
            if not matched_epg and "US" in channel_country_tags and facility:
                fcc_match = EpgService._match_by_fcc_callsign(channel, epg_by_callsign, facility)
                if fcc_match:
                    matched_epg, confidence, match_type = fcc_match
                    stats["matched_fcc_callsign"] += 1
                    logger.debug(
                        f"FCC callsign match: '{channel.name}' -> '{matched_epg.display_name}' "
                        f"via callsign {facility.callsign}"
                    )

            # Strategy 3: Exact match on cleaned name
            if not matched_epg and channel.cleaned_name:
                normalized = EpgService._normalize_name(channel.cleaned_name)
                if normalized and normalized in epg_by_name:
                    matched_epg = epg_by_name[normalized]
                    match_type = "auto_exact"
                    confidence = 0.95
                    stats["matched_exact_name"] += 1

            # Strategy 4: Fuzzy match
            if not matched_epg:
                best_match, best_score = EpgService._fuzzy_match(
                    channel.cleaned_name or channel.name,
                    epg_channels,
                    country_tags=channel_country_tags if channel_country_tags else None,
                )
                if best_match and best_score >= 0.75:
                    matched_epg = best_match
                    match_type = "auto_fuzzy"
                    confidence = best_score
                    stats["matched_fuzzy"] += 1

            # Strategy 5: FCC network fallback (optional, lower priority)
            if not matched_epg and use_network_fallback and "US" in channel_country_tags and facility:
                network_match = EpgService._match_by_fcc_network(channel, epg_by_name, facility)
                if network_match:
                    matched_epg, confidence, match_type = network_match
                    stats["matched_network_fallback"] += 1
                    logger.debug(
                        f"FCC network fallback: '{channel.name}' -> '{matched_epg.display_name}' "
                        f"via network {facility.network_affiliation}"
                    )

            if matched_epg and match_type:
                if channel.id in existing_mappings:
                    mapping = existing_mappings[channel.id]
                    if not mapping.is_override:
                        mapping.epg_channel_id = matched_epg.id
                        mapping.mapping_type = match_type
                        mapping.confidence = confidence
                        mapping.updated_at = datetime.utcnow()
                else:
                    mapping = ChannelEpgMapping(
                        channel_id=channel.id,
                        epg_channel_id=matched_epg.id,
                        mapping_type=match_type,
                        confidence=confidence,
                    )
                    db.session.add(mapping)
            else:
                stats["unmatched"] += 1

            channels_processed += 1
            if channels_processed % batch_size == 0:
                db.session.commit()
                logger.debug(f"EPG matching: Processed {channels_processed}/{len(channels)} channels")

        db.session.commit()

        logger.info(
            f"EPG matching (FCC-enhanced) for account {account_id}{filter_desc}: "
            f"skipped={stats['skipped_existing']}, exact_id={stats['matched_exact_id']}, "
            f"fcc_callsign={stats['matched_fcc_callsign']}, exact_name={stats['matched_exact_name']}, "
            f"fuzzy={stats['matched_fuzzy']}, network_fallback={stats['matched_network_fallback']}, "
            f"unmatched={stats['unmatched']}"
        )

        return stats

    @staticmethod
    def preview_fcc_epg_matches(
        account_id: int,
        source_id: Optional[int] = None,
        limit: int = 100,
    ) -> List[Dict]:
        """
        Preview potential FCC-based EPG matches without applying them.

        Useful for reviewing what matches would be made before committing.

        Args:
            account_id: Account to preview matches for
            source_id: Optional - limit to specific EPG source
            limit: Maximum number of matches to return

        Returns:
            List of dicts with match details
        """
        from services.fcc_facility_service import FccFacilityService

        results: List[Dict] = []

        # Get US-tagged channels without high-confidence EPG mappings
        us_tag = Tag.query.filter(Tag.name.ilike("US")).first()
        if not us_tag:
            return results

        us_channel_stream_ids = set(
            ct.stream_id for ct in ChannelTag.query.filter_by(account_id=account_id, tag_id=us_tag.id).all()
        )

        channels = (
            Channel.query.filter(
                Channel.account_id == account_id,
                Channel.stream_id.in_(us_channel_stream_ids),
                Channel.is_active == True,  # noqa: E712
            )
            .limit(limit * 2)
            .all()
        )

        # Get EPG channels
        epg_query = EpgChannel.query
        if source_id:
            epg_query = epg_query.filter_by(source_id=source_id)
        epg_channels = epg_query.all()

        # Build callsign index
        epg_by_callsign, _ = EpgService._build_fcc_epg_indices(epg_channels)

        for channel in channels:
            if len(results) >= limit:
                break

            facility = EpgService._get_fcc_facility_for_channel(channel)
            if not facility:
                continue

            fcc_match = EpgService._match_by_fcc_callsign(channel, epg_by_callsign, facility)
            if fcc_match:
                matched_epg, confidence, match_type = fcc_match
                results.append(
                    {
                        "channel_id": channel.id,
                        "channel_name": channel.name,
                        "cleaned_name": channel.cleaned_name,
                        "extracted_callsign": FccFacilityService.extract_callsign_from_name(channel.name),
                        "fcc_callsign": facility.callsign,
                        "fcc_city": facility.community_city,
                        "fcc_state": facility.community_state,
                        "fcc_network": facility.network_affiliation,
                        "fcc_dma": facility.nielsen_dma,
                        "epg_channel_id": matched_epg.channel_id,
                        "epg_display_name": matched_epg.display_name,
                        "confidence": confidence,
                        "match_type": match_type,
                    }
                )

        return results

    @staticmethod
    def get_epg_coverage_stats(account_id: Optional[int] = None) -> Dict:
        """
        Get EPG coverage statistics.

        Args:
            account_id: Optional - filter to specific account

        Returns:
            Dict with coverage statistics
        """
        # Count channels with EPG mappings
        mapping_query = db.session.query(ChannelEpgMapping.channel_id).distinct()

        if account_id:
            # Filter to channels from this account
            mapping_query = mapping_query.join(Channel, ChannelEpgMapping.channel_id == Channel.id).filter(
                Channel.account_id == account_id
            )

        mapped_count = mapping_query.count()

        # Count total channels
        channel_query = Channel.query.filter_by(is_active=True)
        if account_id:
            channel_query = channel_query.filter_by(account_id=account_id)
        total_count = channel_query.count()

        # Count channels with provider EPG IDs
        provider_epg_query = Channel.query.filter(
            Channel.is_active == True, Channel.epg_channel_id.isnot(None), Channel.epg_channel_id != ""  # noqa: E712
        )
        if account_id:
            provider_epg_query = provider_epg_query.filter_by(account_id=account_id)
        provider_epg_count = provider_epg_query.count()

        # Count EPG sources and channels
        epg_source_count = EpgSource.query.filter_by(enabled=True).count()
        epg_channel_count = EpgChannel.query.count()

        return {
            "total_channels": total_count,
            "channels_with_provider_epg_id": provider_epg_count,
            "channels_with_epg_mapping": mapped_count,
            "coverage_percent": round((mapped_count / total_count * 100), 1) if total_count > 0 else 0,
            "epg_sources": epg_source_count,
            "epg_channels_available": epg_channel_count,
        }

    @staticmethod
    def get_category_epg_coverage(account_id: int) -> List[Dict]:
        """
        Get EPG coverage broken down by category.

        Args:
            account_id: Account to get stats for

        Returns:
            List of dicts with category info and EPG coverage
        """
        from models import Category

        results = []

        categories = Category.query.filter_by(account_id=account_id).all()

        for category in categories:
            # Count total active channels in category
            total = Channel.query.filter_by(account_id=account_id, category_id=category.id, is_active=True).count()

            if total == 0:
                continue

            # Count channels with provider EPG ID
            with_provider_epg = Channel.query.filter(
                Channel.account_id == account_id,
                Channel.category_id == category.id,
                Channel.is_active == True,  # noqa: E712
                Channel.epg_channel_id.isnot(None),
                Channel.epg_channel_id != "",
            ).count()

            # Count channels with EPG mappings
            with_mapping = (
                db.session.query(Channel.id)
                .join(ChannelEpgMapping, Channel.id == ChannelEpgMapping.channel_id)
                .filter(
                    Channel.account_id == account_id,
                    Channel.category_id == category.id,
                    Channel.is_active == True,  # noqa: E712
                )
                .count()
            )

            results.append(
                {
                    "category_id": category.id,
                    "category_name": category.category_name,
                    "total_channels": total,
                    "with_provider_epg": with_provider_epg,
                    "with_epg_mapping": with_mapping,
                    "coverage_percent": round((with_mapping / total * 100), 1) if total > 0 else 0,
                    "is_ppv": category.is_ppv or False,
                }
            )

        return sorted(results, key=lambda x: x["category_name"])

    @staticmethod
    def create_provider_epg_source(account_id: int) -> EpgSource:
        """
        Create or get an EPG source for a provider account.

        Args:
            account_id: Account ID

        Returns:
            EpgSource instance
        """
        from models import Account

        account = Account.query.get_or_404(account_id)

        # Check if source already exists
        existing = EpgSource.query.filter_by(account_id=account_id, source_type="provider").first()

        if existing:
            return existing

        source = EpgSource(
            name=f"{account.name} (Provider)",
            source_type="provider",
            account_id=account_id,
            priority=50,  # Provider sources get medium priority
            enabled=True,
        )
        db.session.add(source)
        db.session.commit()

        return source

    @staticmethod
    def generate_filtered_epg(
        channel_epg_ids: List[str],
        xml_content: bytes,
        channel_link_map: Optional[Dict[str, Tuple[str, int]]] = None,
        mapping_offset_map: Optional[Dict[str, int]] = None,
    ) -> bytes:
        """
        Generate filtered EPG XML containing only specified channels.

        Uses channel links for EPG fallback - if a channel has a link to a source
        channel, programmes from the source are copied with the specified time offset.

        Args:
            channel_epg_ids: List of EPG channel IDs to include
            xml_content: Source XMLTV XML content (may be gzipped)
            channel_link_map: Optional mapping of channel_epg_id -> (source_epg_id, time_offset_hours)
                              All EPG IDs should be lowercase.
            mapping_offset_map: Optional mapping of epg_channel_id -> time_offset_hours
                               for direct mappings with time offset (from ChannelEpgMapping)

        Returns:
            Filtered XMLTV XML as bytes
        """
        if not channel_epg_ids:
            # Return minimal valid XMLTV
            return b'<?xml version="1.0" encoding="UTF-8"?>\n<tv generator-info-name="iptv-proxy-v2"></tv>\n'

        # Build lookup set for fast channel matching
        requested_ids = set(epg_id.lower() for epg_id in channel_epg_ids if epg_id)

        # Use provided channel_link_map or empty dict
        if channel_link_map is None:
            channel_link_map = {}

        # Use provided mapping_offset_map or empty dict
        if mapping_offset_map is None:
            mapping_offset_map = {}

        # Build reverse lookup: source_epg_id -> list of (target_epg_id, time_offset)
        source_to_targets: Dict[str, List[Tuple[str, int]]] = {}
        for target_id, (source_id, offset) in channel_link_map.items():
            if source_id not in source_to_targets:
                source_to_targets[source_id] = []
            source_to_targets[source_id].append((target_id, offset))

        # Decompress if needed
        stream = get_decompressing_stream(xml_content)

        try:
            # Build result XML
            root = ET.Element("tv")
            root.set("generator-info-name", "iptv-proxy-v2")

            # Track which channels we've found EPG for
            found_channel_ids: Set[str] = set()
            programmes_by_channel: Dict[str, List[ET.Element]] = {}

            # Parse source XMLTV
            context = ET.iterparse(stream, events=("end",))

            for event, elem in context:
                if elem.tag == "channel":
                    channel_id = elem.get("id", "").lower()
                    if channel_id in requested_ids:
                        # Copy channel element
                        new_channel = ET.SubElement(root, "channel")
                        new_channel.set("id", elem.get("id", ""))
                        for child in elem:
                            new_channel.append(_copy_element(child))
                        found_channel_ids.add(channel_id)

                    elem.clear()

                elif elem.tag == "programme":
                    channel_id = elem.get("channel", "").lower()

                    # Direct match
                    if channel_id in requested_ids:
                        if channel_id not in programmes_by_channel:
                            programmes_by_channel[channel_id] = []
                        prog_copy = _copy_element(elem)
                        # Apply mapping offset if present
                        mapping_offset = mapping_offset_map.get(channel_id, 0)
                        if mapping_offset != 0:
                            start = prog_copy.get("start")
                            stop = prog_copy.get("stop")
                            if start:
                                prog_copy.set("start", shift_xmltv_time(start, mapping_offset))
                            if stop:
                                prog_copy.set("stop", shift_xmltv_time(stop, mapping_offset))
                        programmes_by_channel[channel_id].append(prog_copy)

                    # Check if this is a source channel for any linked channels
                    if channel_id in source_to_targets:
                        for target_id, time_offset in source_to_targets[channel_id]:
                            if target_id not in programmes_by_channel:
                                programmes_by_channel[target_id] = []
                            shifted_prog = _copy_element(elem)
                            # Apply time offset
                            shifted_prog.set("channel", target_id)
                            if time_offset != 0:
                                start = shifted_prog.get("start")
                                stop = shifted_prog.get("stop")
                                if start:
                                    shifted_prog.set("start", shift_xmltv_time(start, time_offset))
                                if stop:
                                    shifted_prog.set("stop", shift_xmltv_time(stop, time_offset))
                            programmes_by_channel[target_id].append(shifted_prog)

                    elem.clear()

            # Add linked channels that weren't in original EPG but got programmes from source
            for target_id in channel_link_map.keys():
                if target_id not in found_channel_ids and target_id in programmes_by_channel:
                    # Create a channel entry for this linked channel
                    new_channel = ET.SubElement(root, "channel")
                    new_channel.set("id", target_id)
                    display_name = ET.SubElement(new_channel, "display-name")
                    display_name.text = target_id  # Basic fallback name

            # Add all programme elements
            for channel_id in sorted(programmes_by_channel.keys()):
                for prog in programmes_by_channel[channel_id]:
                    root.append(prog)

        finally:
            stream.close()

        # Generate XML output
        return ET.tostring(root, encoding="unicode", xml_declaration=True).encode("utf-8")

    @staticmethod
    def _build_channel_link_map(channel_ids: List[int]) -> Dict[str, Tuple[str, int]]:
        """
        Build a mapping from channels to their linked source channels.

        For channels with a ChannelLink, returns their source channel's EPG ID
        and the time offset to apply.

        Args:
            channel_ids: List of channel IDs (db primary keys) to check

        Returns:
            Dict mapping channel_epg_id -> (source_epg_id, time_offset_hours)
            All EPG IDs are lowercase.
        """
        from models import ChannelLink

        if not channel_ids:
            return {}

        link_map: Dict[str, Tuple[str, int]] = {}

        # Query all links for the given channels
        links = (
            ChannelLink.query.filter(ChannelLink.channel_id.in_(channel_ids))
            .options(
                db.joinedload(ChannelLink.channel),
                db.joinedload(ChannelLink.source_channel),
            )
            .all()
        )

        for link in links:
            if link.channel and link.source_channel:
                channel_epg_id = link.channel.epg_channel_id
                source_epg_id = link.source_channel.epg_channel_id

                if channel_epg_id and source_epg_id:
                    link_map[channel_epg_id.lower()] = (source_epg_id.lower(), link.time_offset_hours)

        return link_map

    @staticmethod
    def _build_mapping_offset_map(channel_ids: List[int]) -> Dict[str, int]:
        """
        Build a mapping of EPG channel IDs to their time offsets from ChannelEpgMapping.

        For channels with a manual EPG mapping that has a non-zero time offset,
        returns a dict mapping the EPG channel's XMLTV ID to the offset.

        Args:
            channel_ids: List of channel IDs (db primary keys) to check

        Returns:
            Dict mapping epg_channel_xmltv_id (lowercase) -> time_offset_hours
        """
        if not channel_ids:
            return {}

        offset_map: Dict[str, int] = {}

        # Query mappings with non-zero time offset
        mappings = (
            ChannelEpgMapping.query.filter(
                ChannelEpgMapping.channel_id.in_(channel_ids),
                ChannelEpgMapping.time_offset_hours != 0,
            )
            .options(db.joinedload(ChannelEpgMapping.epg_channel))
            .all()
        )

        for mapping in mappings:
            if mapping.epg_channel and mapping.epg_channel.channel_id:
                # Use the XMLTV channel ID (lowercase) as the key
                xmltv_id = mapping.epg_channel.channel_id.lower()
                offset_map[xmltv_id] = mapping.time_offset_hours

        return offset_map

    @staticmethod
    def generate_epg_for_channels(
        channels: List[Channel],
        account_xml_cache: Optional[Dict[int, bytes]] = None,
        use_channel_links: bool = True,
    ) -> bytes:
        """
        Generate EPG XML for a list of channels.

        Fetches XMLTV data from accounts and filters to only include
        the specified channels. Uses ChannelLink for fallback EPG sources.

        Args:
            channels: List of Channel objects to generate EPG for
            account_xml_cache: Optional pre-fetched XML content by account ID
            use_channel_links: Whether to use ChannelLink for fallback EPG

        Returns:
            XMLTV XML content as bytes
        """
        from services.iptv_service import IPTVService

        if not channels:
            return b'<?xml version="1.0" encoding="UTF-8"?>\n<tv generator-info-name="iptv-proxy-v2"></tv>\n'

        channel_ids = [ch.id for ch in channels]

        # Build channel link map if enabled
        channel_link_map: Dict[str, Tuple[str, int]] = {}
        if use_channel_links:
            channel_link_map = EpgService._build_channel_link_map(channel_ids)

        # Build mapping offset map for time shifts from ChannelEpgMapping
        mapping_offset_map = EpgService._build_mapping_offset_map(channel_ids)

        # Group channels by account
        channels_by_account: Dict[int, List[Channel]] = {}
        for ch in channels:
            if ch.account_id not in channels_by_account:
                channels_by_account[ch.account_id] = []
            channels_by_account[ch.account_id].append(ch)

        # Build combined EPG
        root = ET.Element("tv")
        root.set("generator-info-name", "iptv-proxy-v2")

        all_channel_elements: List[ET.Element] = []
        all_programme_elements: List[ET.Element] = []

        for account_id, account_channels in channels_by_account.items():
            # Build mapping: provider_epg_id -> (channel, standardized_id)
            # This allows us to fetch EPG using provider IDs but output our standardized IDs
            epg_id_mapping: Dict[str, List[Tuple[Channel, str]]] = {}

            for ch in account_channels:
                standardized_id = f"ch-{account_id}-{ch.stream_id}"
                if ch.epg_channel_id:
                    # Channel has matched EPG data - map provider ID to our ID
                    provider_id_lower = ch.epg_channel_id.lower()
                    if provider_id_lower not in epg_id_mapping:
                        epg_id_mapping[provider_id_lower] = []
                    epg_id_mapping[provider_id_lower].append((ch, standardized_id))

            # Get unique provider EPG IDs that have actual EPG data
            provider_epg_ids = list(epg_id_mapping.keys())

            if not provider_epg_ids:
                # No channels with EPG mappings, skip fetching XMLTV
                continue

            # Get XMLTV content for this account
            xml_content = None
            if account_xml_cache and account_id in account_xml_cache:
                xml_content = account_xml_cache[account_id]
            else:
                # Fetch from account
                from models import Account

                account = db.session.get(Account, account_id)
                if account and account.enabled:
                    try:
                        cred = account.get_primary_credential()
                        if cred:
                            service = IPTVService(
                                account.server,
                                cred.username,
                                cred.password,
                                account.user_agent or "okhttp/3.14.9",
                            )
                        else:
                            service = IPTVService(
                                account.server,
                                account.username,
                                account.password,
                                account.user_agent or "okhttp/3.14.9",
                            )
                        xml_content = service.get_xmltv()
                    except Exception as e:
                        logger.warning(f"Failed to fetch EPG for account {account_id}: {e}")
                        continue

            if not xml_content:
                continue

            # Generate filtered EPG using provider IDs, then remap to standardized IDs
            filtered_xml = EpgService.generate_filtered_epg(
                provider_epg_ids, xml_content, channel_link_map=channel_link_map, mapping_offset_map=mapping_offset_map
            )

            # Parse and remap channel IDs to our standardized format
            try:
                filtered_root = ET.fromstring(filtered_xml)
                for elem in filtered_root:
                    if elem.tag == "channel":
                        provider_id = elem.get("id", "").lower()
                        if provider_id in epg_id_mapping:
                            # Remap to first standardized ID (if multiple channels share provider ID, they share EPG)
                            _, standardized_id = epg_id_mapping[provider_id][0]
                            elem.set("id", standardized_id)
                            all_channel_elements.append(elem)
                    elif elem.tag == "programme":
                        provider_id = elem.get("channel", "").lower()
                        if provider_id in epg_id_mapping:
                            # Create programme entries for each channel that maps to this provider ID
                            for _, standardized_id in epg_id_mapping[provider_id]:
                                prog_copy = _copy_element(elem)
                                prog_copy.set("channel", standardized_id)
                                all_programme_elements.append(prog_copy)
            except ET.ParseError as e:
                logger.warning(f"Failed to parse filtered EPG for account {account_id}: {e}")
                continue

        # Add synthetic channel elements for channels without epg_channel_id
        # These use standardized IDs but have no program data
        added_fallback_ids: Set[str] = set()

        for account_id, account_channels in channels_by_account.items():
            for ch in account_channels:
                if not ch.epg_channel_id:
                    # Create synthetic channel element with fallback ID
                    fallback_id = f"ch-{account_id}-{ch.stream_id}"

                    # Skip if we already added this ID
                    if fallback_id in added_fallback_ids:
                        continue

                    added_fallback_ids.add(fallback_id)
                    channel_elem = ET.Element("channel", id=fallback_id)

                    # Add display name
                    display_name_elem = ET.SubElement(channel_elem, "display-name")
                    display_name_elem.text = ch.cleaned_name or ch.name

                    # Add icon if available
                    if ch.stream_icon:
                        ET.SubElement(channel_elem, "icon", src=ch.stream_icon)

                    all_channel_elements.append(channel_elem)
                    logger.debug(f"Added synthetic EPG channel for {ch.name} with ID {fallback_id}")

        # Add all channel elements first, then programmes
        for elem in all_channel_elements:
            root.append(elem)
        for elem in all_programme_elements:
            root.append(elem)

        return ET.tostring(root, encoding="unicode", xml_declaration=True).encode("utf-8")


def _copy_element(elem: ET.Element) -> ET.Element:
    """
    Deep copy an XML element.

    Args:
        elem: Element to copy

    Returns:
        New element with all attributes and children copied
    """
    new_elem = ET.Element(elem.tag, elem.attrib)
    new_elem.text = elem.text
    new_elem.tail = elem.tail
    for child in elem:
        new_elem.append(_copy_element(child))
    return new_elem


def update_ppv_channel_visibility(account_id: Optional[int] = None) -> Dict[str, int]:
    """
    Update visibility of PPV channels based on channel name changes.

    PPV channels from IPTV providers have placeholder names like "PPV 1" when no
    event is scheduled. When an event IS scheduled, the provider changes the
    channel name to the event title (e.g., "UFC 300: Main Event").

    This function:
    1. Finds all PPV channels (by tag or category)
    2. Checks if channel name is a placeholder (no event) or event title
    3. Hides placeholder channels, shows channels with event titles

    Note: PPV channels don't have external EPG data. Detection is purely based
    on the channel name in the playlist.

    Args:
        account_id: Optional account ID to limit updates to specific account

    Returns:
        Dict with statistics: {
            'total_ppv_channels': int,
            'channels_shown': int,
            'channels_hidden': int,
            'events_detected': int
        }
    """
    stats = {
        "total_ppv_channels": 0,
        "channels_shown": 0,
        "channels_hidden": 0,
        "events_detected": 0,
    }

    # Get all channels with PPV tag
    ppv_tag = Tag.query.filter_by(name="PPV").first()
    if not ppv_tag:
        logger.info("No PPV tag found, skipping PPV channel visibility update")
        return stats

    # Query for channels with PPV tag
    query = (
        db.session.query(Channel)
        .join(
            ChannelTag, db.and_(Channel.account_id == ChannelTag.account_id, Channel.stream_id == ChannelTag.stream_id)
        )
        .filter(ChannelTag.tag_id == ppv_tag.id, Channel.is_active == True)  # noqa: E712
    )

    if account_id:
        query = query.filter(Channel.account_id == account_id)

    ppv_channels = query.all()
    stats["total_ppv_channels"] = len(ppv_channels)

    if not ppv_channels:
        logger.info("No PPV channels found")
        return stats

    logger.info(f"Checking {len(ppv_channels)} PPV channel(s) for visibility updates")

    # Update each PPV channel's visibility based on its name
    for channel in ppv_channels:
        # Check if channel name is a placeholder (no event) or actual event title
        is_placeholder = is_ppv_placeholder_name(channel.name)

        if is_placeholder:
            # Placeholder name - hide the channel
            if channel.is_visible:
                channel.is_visible = False
                stats["channels_hidden"] += 1
                logger.info(f"Hiding PPV channel '{channel.name}' (placeholder name)")
        else:
            # Actual event title - show the channel
            stats["events_detected"] += 1
            if not channel.is_visible:
                channel.is_visible = True
                stats["channels_shown"] += 1
                logger.info(f"Showing PPV channel with event: '{channel.name}'")

    # Commit all visibility changes
    try:
        db.session.commit()
        logger.info(
            f"PPV visibility update complete: "
            f"{stats['events_detected']} events detected, "
            f"{stats['channels_shown']} shown, {stats['channels_hidden']} hidden"
        )
    except Exception as e:
        logger.error(f"Error committing PPV visibility changes: {e}")
        db.session.rollback()

    return stats


def generate_ppv_epg_entries(account_id: Optional[int] = None, duration_hours: int = 8) -> List[Dict]:
    """
    Generate synthetic EPG entries for active PPV channels.

    Since PPV channels don't have external EPG data, we generate EPG entries
    using the channel name as the program title. This allows the EPG to show
    what event is currently scheduled on each PPV channel.

    Args:
        account_id: Optional account ID to limit to specific account
        duration_hours: How long each PPV event should appear in EPG (default: 8 hours)

    Returns:
        List of EPG program entries in XMLTV format:
        [
            {
                'channel_id': 'ppv-101-12345',
                'title': 'UFC 300: Main Event',
                'start': '20231215180000 +0000',
                'stop': '20231216020000 +0000',
                'desc': 'Pay-Per-View Event',
                'category': 'Sports'
            },
            ...
        ]
    """
    programs: List[Dict[str, Any]] = []

    # Get all visible PPV channels (only those with active events)
    ppv_tag = Tag.query.filter_by(name="PPV").first()
    if not ppv_tag:
        return programs

    query = (
        db.session.query(Channel)
        .join(
            ChannelTag, db.and_(Channel.account_id == ChannelTag.account_id, Channel.stream_id == ChannelTag.stream_id)
        )
        .filter(
            ChannelTag.tag_id == ppv_tag.id,
            Channel.is_active == True,  # noqa: E712
            Channel.is_visible == True,  # noqa: E712
        )
    )

    if account_id:
        query = query.filter(Channel.account_id == account_id)

    active_ppv_channels = query.all()

    if not active_ppv_channels:
        return programs

    # Generate EPG entry for each active PPV channel
    now = datetime.utcnow()
    end_time = now + timedelta(hours=duration_hours)

    # Format times in XMLTV format
    start_str = now.strftime("%Y%m%d%H%M%S") + " +0000"
    stop_str = end_time.strftime("%Y%m%d%H%M%S") + " +0000"

    for channel in active_ppv_channels:
        event_title = get_ppv_event_title(channel)
        if not event_title:
            continue

        # Generate a unique EPG channel ID for this PPV channel
        epg_channel_id = f"ppv-{channel.stream_id}-{channel.account_id}"

        program = {
            "channel_id": epg_channel_id,
            "title": event_title,
            "start": start_str,
            "stop": stop_str,
            "desc": "Pay-Per-View Event",
            "category": "Sports",  # Most PPV is sports-related
        }
        programs.append(program)

        logger.debug(f"Generated PPV EPG entry for '{event_title}' on channel {channel.stream_id}")

    logger.info(f"Generated {len(programs)} PPV EPG entries")
    return programs


def get_ppv_epg_xmltv(account_id: Optional[int] = None, duration_hours: int = 8) -> bytes:
    """
    Generate XMLTV data for active PPV channels.

    This creates a valid XMLTV document containing channel definitions
    and program entries for all active PPV events.

    Args:
        account_id: Optional account ID to limit to specific account
        duration_hours: How long each PPV event should appear in EPG

    Returns:
        XMLTV XML data as bytes
    """
    root = ET.Element("tv")
    root.set("source-info-name", "IPTV Proxy PPV EPG")
    root.set("generator-info-name", "iptv-proxy-v2")

    # Get active PPV channels
    ppv_tag = Tag.query.filter_by(name="PPV").first()
    if not ppv_tag:
        return ET.tostring(root, encoding="unicode", xml_declaration=True).encode("utf-8")

    query = (
        db.session.query(Channel)
        .join(
            ChannelTag, db.and_(Channel.account_id == ChannelTag.account_id, Channel.stream_id == ChannelTag.stream_id)
        )
        .filter(
            ChannelTag.tag_id == ppv_tag.id,
            Channel.is_active == True,  # noqa: E712
            Channel.is_visible == True,  # noqa: E712
        )
    )

    if account_id:
        query = query.filter(Channel.account_id == account_id)

    active_ppv_channels = query.all()

    if not active_ppv_channels:
        return ET.tostring(root, encoding="unicode", xml_declaration=True).encode("utf-8")

    # Time for programs
    now = datetime.utcnow()
    end_time = now + timedelta(hours=duration_hours)
    start_str = now.strftime("%Y%m%d%H%M%S") + " +0000"
    stop_str = end_time.strftime("%Y%m%d%H%M%S") + " +0000"

    # Add channels and programs
    for channel in active_ppv_channels:
        event_title = get_ppv_event_title(channel)
        if not event_title:
            continue

        epg_channel_id = f"ppv-{channel.stream_id}-{channel.account_id}"

        # Add channel element
        channel_elem = ET.SubElement(root, "channel", id=epg_channel_id)
        display_name = ET.SubElement(channel_elem, "display-name")
        display_name.text = event_title

        if channel.stream_icon:
            icon = ET.SubElement(channel_elem, "icon", src=channel.stream_icon)  # noqa: F841

        # Add program element
        programme = ET.SubElement(root, "programme", start=start_str, stop=stop_str, channel=epg_channel_id)

        title_elem = ET.SubElement(programme, "title", lang="en")
        title_elem.text = event_title

        desc_elem = ET.SubElement(programme, "desc", lang="en")
        desc_elem.text = "Pay-Per-View Event"

        category_elem = ET.SubElement(programme, "category", lang="en")
        category_elem.text = "Sports"

    return ET.tostring(root, encoding="unicode", xml_declaration=True).encode("utf-8")
