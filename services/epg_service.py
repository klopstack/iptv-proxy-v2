"""
EPG (Electronic Program Guide) Service

Handles parsing XMLTV data, matching EPG channels to our channels,
and managing EPG sources.

XMLTV Channel ID Formats:
- Provider XMLTV: Typically textual like "ESPN.us", "AntennaTV.us", "BBC1.uk"
- Schedules Direct: "I{station_id}.json.schedulesdirect.org" (e.g., "I10021.json.schedulesdirect.org")
- Generic: Can be any string identifier

Matching Strategy:
Since XMLTV IDs from providers are textual (callsign-based) and Schedules Direct
uses numeric station IDs, we match channels using:
1. Exact callsign matching (extracting from XMLTV ID format)
2. Exact name matching
3. Fuzzy name matching

East/West Channel Handling:
Many US channels have east and west coast feeds (e.g., "HBO East", "HBO West").
EPG data often only contains listings for the east feed or without geographic identifier.
West feed EPG is generated by shifting east feed times by -3 hours.
"""
import gzip
import io
import json
import logging
import re
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from difflib import SequenceMatcher
from typing import Dict, Iterator, List, Optional, Set, Tuple

from models import Channel, ChannelEpgMapping, ChannelTag, EpgChannel, EpgSource, FccFacility, Tag, db

logger = logging.getLogger(__name__)

# Major broadcast networks that should match EPG network channels
MAJOR_BROADCAST_NETWORKS = {"ABC", "NBC", "CBS", "FOX", "PBS", "CW", "ION"}

# Common country code mappings from tags to XMLTV ID suffixes
COUNTRY_TAG_TO_SUFFIX = {
    "US": [".us", ".us2", "us"],
    "UK": [".uk", "uk"],
    "CA": [".ca", "ca"],
    "AU": [".au", "au"],
    "DE": [".de", "de"],
    "FR": [".fr", "fr"],
    "ES": [".es", "es"],
    "IT": [".it", "it"],
    "NL": [".nl", "nl"],
    "BE": [".be", "be"],
    "PL": [".pl", "pl"],
    "PT": [".pt", "pt"],
    "BR": [".br", "br"],
    "MX": [".mx", "mx"],
    "IN": [".in", "in"],
    "JP": [".jp", "jp"],
}


def extract_callsign_from_xmltv_id(xmltv_id: str) -> Optional[str]:
    """
    Extract a callsign/identifier from various XMLTV channel ID formats.

    Args:
        xmltv_id: The XMLTV channel ID string

    Returns:
        Extracted callsign or None if extraction fails

    Examples:
        "ESPN.us" -> "ESPN"
        "AntennaTV.us" -> "AntennaTV"
        "I10021.json.schedulesdirect.org" -> "10021"
        "BBC One" -> "BBC One"
        "CNN" -> "CNN"
    """
    if not xmltv_id:
        return None

    # Pattern 1: Schedules Direct format (I{station_id}.json.schedulesdirect.org)
    sd_match = re.match(r"I(\d+)\.json\.schedulesdirect\.org", xmltv_id, re.IGNORECASE)
    if sd_match:
        return sd_match.group(1)

    # Pattern 2: CALLSIGN.country or CALLSIGN.tld (e.g., ESPN.us, BBC1.uk)
    # Match alphanumeric callsign before the first dot
    dot_match = re.match(r"^([A-Za-z0-9]+(?:[A-Za-z0-9\-]*[A-Za-z0-9])?)\.(?:[a-z]{2,}|[A-Z]{2,})$", xmltv_id)
    if dot_match:
        return dot_match.group(1)

    # Pattern 3: Return as-is if it looks like a simple callsign (no dots, reasonable length)
    if "." not in xmltv_id and len(xmltv_id) <= 20:
        return xmltv_id

    # Pattern 4: Try to extract first segment before any dot
    if "." in xmltv_id:
        first_segment = xmltv_id.split(".")[0]
        if first_segment and len(first_segment) >= 2:
            return first_segment

    return xmltv_id


def make_sd_xmltv_id(station_id: str) -> str:
    """
    Create a Schedules Direct style XMLTV channel ID.

    Args:
        station_id: The numeric Schedules Direct station ID

    Returns:
        XMLTV-format ID like "I10021.json.schedulesdirect.org"
    """
    return f"I{station_id}.json.schedulesdirect.org"


def normalize_xmltv_url(url: str) -> str:
    """
    Normalize an XMLTV URL to ensure it returns raw content.

    Converts GitHub blob URLs to raw.githubusercontent.com URLs.

    Args:
        url: The URL to normalize

    Returns:
        The normalized URL

    Examples:
        "https://github.com/user/repo/blob/main/guide.xml"
        -> "https://raw.githubusercontent.com/user/repo/main/guide.xml"
    """
    # Convert GitHub blob URLs to raw URLs
    github_blob_pattern = r"^https?://github\.com/([^/]+)/([^/]+)/blob/(.+)$"
    match = re.match(github_blob_pattern, url)
    if match:
        owner, repo, path = match.groups()
        return f"https://raw.githubusercontent.com/{owner}/{repo}/{path}"
    return url


# ============================================================================
# Channel Link EPG Handling
# ============================================================================

# Tag names that indicate east/west variants (used for auto-detection during sync)
EAST_TAGS = {"EAST", "E", "ET", "EST", "EASTERN"}
WEST_TAGS = {"WEST", "W", "PT", "PST", "PACIFIC", "WESTERN"}


def shift_xmltv_time(time_str: str, hours: int) -> str:
    """
    Shift an XMLTV datetime string by a number of hours.

    XMLTV format: YYYYMMDDHHmmss +ZZZZ (e.g., "20231215140000 +0000")

    Args:
        time_str: XMLTV datetime string
        hours: Number of hours to shift (negative for earlier)

    Returns:
        Shifted XMLTV datetime string
    """
    if not time_str:
        return time_str

    # Split off timezone if present
    parts = time_str.split()
    datetime_part = parts[0]
    tz_part = parts[1] if len(parts) > 1 else "+0000"

    # Parse datetime
    try:
        if len(datetime_part) >= 14:
            dt = datetime.strptime(datetime_part[:14], "%Y%m%d%H%M%S")
        elif len(datetime_part) >= 12:
            dt = datetime.strptime(datetime_part[:12], "%Y%m%d%H%M")
        elif len(datetime_part) >= 8:
            dt = datetime.strptime(datetime_part[:8], "%Y%m%d")
        else:
            return time_str
    except ValueError:
        return time_str

    # Apply shift
    dt = dt + timedelta(hours=hours)

    # Format back to XMLTV format
    return f"{dt.strftime('%Y%m%d%H%M%S')} {tz_part}"


def decompress_content(content: bytes) -> bytes:
    """
    Decompress gzipped content if necessary.

    Args:
        content: Raw bytes that may be gzip-compressed

    Returns:
        Decompressed bytes, or original content if not gzipped
    """
    # Check for gzip magic bytes
    if content[:2] == b"\x1f\x8b":
        try:
            return gzip.decompress(content)
        except gzip.BadGzipFile:
            logger.warning("Content has gzip header but failed to decompress")
            return content
    return content


def get_decompressing_stream(content: bytes) -> io.BufferedIOBase:
    """
    Get a file-like object for reading content, with streaming decompression if gzipped.

    Args:
        content: Raw bytes that may be gzip-compressed

    Returns:
        A file-like object for reading the (decompressed) content
    """
    # Check for gzip magic bytes
    if content[:2] == b"\x1f\x8b":
        # Use streaming gzip decompression
        return gzip.GzipFile(fileobj=io.BytesIO(content), mode="rb")
    return io.BytesIO(content)


class EpgService:
    """Service for managing EPG data and channel matching"""

    @staticmethod
    def parse_xmltv_streaming(xml_content: bytes) -> Iterator[Tuple[str, Dict]]:
        """
        Parse XMLTV content using streaming parser for memory efficiency.
        Yields channel and programme elements one at a time.

        Args:
            xml_content: Raw XMLTV XML bytes (may be gzip-compressed)

        Yields:
            Tuples of (element_type, data) where element_type is 'channel' or 'programme'
        """
        stream = get_decompressing_stream(xml_content)

        try:
            # Use iterparse for memory-efficient parsing
            context = ET.iterparse(stream, events=("end",))

            for event, elem in context:
                if elem.tag == "channel":
                    channel_id = elem.get("id")
                    if channel_id:
                        display_names = []
                        for dn in elem.findall("display-name"):
                            if dn.text:
                                display_names.append(dn.text.strip())

                        icon_url = None
                        icon_elem = elem.find("icon")
                        if icon_elem is not None:
                            icon_url = icon_elem.get("src")

                        url = None
                        url_elem = elem.find("url")
                        if url_elem is not None and url_elem.text:
                            url = url_elem.text.strip()

                        yield (
                            "channel",
                            {
                                "channel_id": channel_id,
                                "display_names": display_names,
                                "display_name": display_names[0] if display_names else channel_id,
                                "icon_url": icon_url,
                                "url": url,
                            },
                        )

                    # Clear element to free memory
                    elem.clear()

                elif elem.tag == "programme":
                    channel_id = elem.get("channel")
                    if channel_id:
                        yield (
                            "programme",
                            {
                                "channel": channel_id,
                                "start": elem.get("start"),
                                "stop": elem.get("stop"),
                            },
                        )

                    # Clear element to free memory
                    elem.clear()

                # Also clear any ancestors to prevent memory buildup
                # This is needed because iterparse keeps a reference to parent elements
                if elem.tag in ("channel", "programme"):
                    # Clear the element's tail text
                    elem.tail = None

        except ET.ParseError as e:
            logger.error(f"Failed to parse XMLTV: {e}")
            raise ValueError(f"Invalid XMLTV XML: {e}")
        finally:
            stream.close()

    @staticmethod
    def parse_xmltv(xml_content: bytes) -> Dict:
        """
        Parse XMLTV content and extract channel information.

        Uses streaming parser internally for memory efficiency with large files.

        Args:
            xml_content: Raw XMLTV XML bytes (may be gzip-compressed)

        Returns:
            Dict with 'channels' list and 'programs_by_channel' dict
        """
        channels = []
        programs_by_channel: Dict[str, List[Dict]] = {}

        for element_type, data in EpgService.parse_xmltv_streaming(xml_content):
            if element_type == "channel":
                channels.append(data)
                programs_by_channel[data["channel_id"]] = []
            elif element_type == "programme":
                channel_id = data["channel"]
                if channel_id in programs_by_channel:
                    programs_by_channel[channel_id].append(
                        {
                            "start": data["start"],
                            "stop": data["stop"],
                        }
                    )

        return {
            "channels": channels,
            "programs_by_channel": programs_by_channel,
        }

    @staticmethod
    def sync_epg_source(source: EpgSource, xml_content: bytes) -> Dict:
        """
        Sync EPG data from XMLTV content into the database.

        Uses streaming parser for memory efficiency with large files.

        Args:
            source: The EpgSource to sync
            xml_content: Raw XMLTV XML bytes

        Returns:
            Dict with sync statistics
        """
        stats = {
            "channels_added": 0,
            "channels_updated": 0,
            "channels_removed": 0,
            "total_programs": 0,
        }

        now = datetime.utcnow()
        seen_channel_ids: Set[str] = set()

        # Track channel data and program stats as we stream
        # We only keep essential info in memory, not all program details
        channel_data_map: Dict[str, Dict] = {}
        channel_program_stats: Dict[str, Dict] = {}  # channel_id -> {count, first_time, last_time}

        # Stream through the XMLTV content
        try:
            for element_type, data in EpgService.parse_xmltv_streaming(xml_content):
                if element_type == "channel":
                    channel_id = data["channel_id"]
                    if channel_id in channel_data_map:
                        # Handle duplicate channel entries by merging display names
                        existing = channel_data_map[channel_id]
                        existing_names = existing.get("display_names", [])
                        new_names = data.get("display_names", [])
                        merged_names = list(dict.fromkeys(existing_names + new_names))
                        existing["display_names"] = merged_names
                        if not existing.get("icon_url") and data.get("icon_url"):
                            existing["icon_url"] = data.get("icon_url")
                        if not existing.get("url") and data.get("url"):
                            existing["url"] = data.get("url")
                        logger.debug(f"Merged duplicate channel ID '{channel_id}' in XMLTV data")
                    else:
                        channel_data_map[channel_id] = data
                        channel_program_stats[channel_id] = {
                            "count": 0,
                            "first_time": None,
                            "last_time": None,
                        }
                    seen_channel_ids.add(channel_id)

                elif element_type == "programme":
                    channel_id = data["channel"]
                    if channel_id in channel_program_stats:
                        prog_stats = channel_program_stats[channel_id]
                        prog_stats["count"] += 1
                        stats["total_programs"] += 1

                        # Track time range without storing all times
                        for time_field in ("start", "stop"):
                            time_str = data.get(time_field)
                            if time_str:
                                try:
                                    t = EpgService._parse_xmltv_time(time_str)
                                    if t:
                                        if prog_stats["first_time"] is None or t < prog_stats["first_time"]:
                                            prog_stats["first_time"] = t
                                        if prog_stats["last_time"] is None or t > prog_stats["last_time"]:
                                            prog_stats["last_time"] = t
                                except Exception:
                                    pass

        except ValueError as e:
            source.last_sync = datetime.utcnow()
            source.last_sync_status = "error"
            source.last_sync_message = str(e)
            db.session.commit()
            raise

        # Track channels we've already processed in THIS sync
        processed_in_this_sync: Dict[str, EpgChannel] = {}

        # Get existing channels for this source
        existing = {ec.channel_id: ec for ec in EpgChannel.query.filter_by(source_id=source.id).all()}

        # Now update the database with collected channel data
        for channel_id, channel_data in channel_data_map.items():
            prog_stats = channel_program_stats.get(channel_id, {"count": 0, "first_time": None, "last_time": None})
            program_count = prog_stats["count"]
            first_program = prog_stats["first_time"]
            last_program = prog_stats["last_time"]

            if channel_id in existing:
                # Update existing channel from database
                ec = existing[channel_id]
                ec.display_name = channel_data["display_name"]
                ec.display_names_json = json.dumps(channel_data["display_names"])
                ec.icon_url = channel_data.get("icon_url")
                ec.url = channel_data.get("url")
                ec.program_count = program_count
                ec.first_program = first_program
                ec.last_program = last_program
                ec.last_seen = now
                ec.updated_at = now
                stats["channels_updated"] += 1
            else:
                # Create new channel
                ec = EpgChannel(
                    source_id=source.id,
                    channel_id=channel_id,
                    display_name=channel_data["display_name"],
                    display_names_json=json.dumps(channel_data["display_names"]),
                    icon_url=channel_data.get("icon_url"),
                    url=channel_data.get("url"),
                    program_count=program_count,
                    first_program=first_program,
                    last_program=last_program,
                    last_seen=now,
                )
                db.session.add(ec)
                processed_in_this_sync[channel_id] = ec
                stats["channels_added"] += 1

        # Mark channels not seen as removed (but don't delete - they may come back)
        for channel_id, ec in existing.items():
            if channel_id not in seen_channel_ids:
                stats["channels_removed"] += 1

        # Update source stats
        source.last_sync = now
        source.last_sync_status = "success"
        source.last_sync_message = f"Synced {len(seen_channel_ids)} channels, {stats['total_programs']} programs"
        source.channel_count = len(seen_channel_ids)
        source.updated_at = now

        db.session.commit()

        logger.info(
            f"EPG sync for source {source.id} ({source.name}): "
            f"added={stats['channels_added']}, updated={stats['channels_updated']}, "
            f"programs={stats['total_programs']}"
        )

        return stats

    @staticmethod
    def _parse_xmltv_time(time_str: str) -> Optional[datetime]:
        """Parse XMLTV datetime format (YYYYMMDDHHmmss +ZZZZ)"""
        if not time_str:
            return None

        # Remove timezone for basic parsing (just need date range)
        time_str = time_str.split()[0]  # Remove timezone offset
        try:
            return datetime.strptime(time_str, "%Y%m%d%H%M%S")
        except ValueError:
            try:
                return datetime.strptime(time_str, "%Y%m%d%H%M")
            except ValueError:
                return None

    @staticmethod
    def _build_callsign_epg_index(epg_channels: List[EpgChannel]) -> Dict[str, EpgChannel]:
        """
        Build an index of EPG channels by callsign for tag-based matching.

        Extracts callsigns from EPG channel IDs (e.g., "WCTI-DT.us_locals1" -> "WCTI")
        and strips common suffixes (-DT, -TV, -HD, etc.) to match against callsign tags.

        Args:
            epg_channels: List of EPG channels to index

        Returns:
            Dict mapping uppercase callsigns to EPG channels
        """
        epg_by_callsign: Dict[str, EpgChannel] = {}

        for ec in epg_channels:
            # Extract callsign from channel_id
            callsign = extract_callsign_from_xmltv_id(ec.channel_id)
            if callsign:
                callsign_upper = callsign.upper()
                # Only index if it looks like a broadcast callsign (starts with K or W)
                if len(callsign_upper) >= 3 and callsign_upper[0] in ("K", "W"):
                    # Store the full callsign
                    epg_by_callsign[callsign_upper] = ec

                    # Also store base callsign without common suffixes (-DT, -TV, -HD, -CD, -LP, etc.)
                    base_callsign = re.sub(r"-(DT|TV|HD|CD|LP|FM|DT2?|TV2?)$", "", callsign_upper, flags=re.IGNORECASE)
                    if base_callsign != callsign_upper and len(base_callsign) >= 3:
                        # Only add base if not already present (prefer exact match)
                        if base_callsign not in epg_by_callsign:
                            epg_by_callsign[base_callsign] = ec

        return epg_by_callsign

    @staticmethod
    def _lookup_fcc_callsign(
        channel_name: str,
        channel_tags: Set[str],
        network_tags: Set[str],
    ) -> Optional[str]:
        """
        Look up a callsign from FCC data using channel info.

        Uses city/location tags, network tags, and channel number extracted from name
        to find matching FCC facility records. Also tries to extract city names
        and callsigns from the channel name itself.

        Args:
            channel_name: The cleaned channel name (e.g., "ABC 10 ALBANY" or "ABC 3 WSIL")
            channel_tags: All tags for this channel (uppercase)
            network_tags: Tags that are known broadcast networks (e.g., ABC, NBC)

        Returns:
            Callsign string if found, None otherwise
        """
        # Extract channel numbers from name (look for standalone numbers or compound like "33/40")
        # This handles cases like "ABC 33/40 HD [BIRMINGHAM]" where we try both 33 and 40
        channel_numbers: List[int] = []

        # First, look for compound channel numbers like "33/40"
        compound_match = re.search(r"\b(\d{1,2})/(\d{1,2})\b", channel_name)
        if compound_match:
            channel_numbers.extend([int(compound_match.group(1)), int(compound_match.group(2))])
            logger.debug(f"FCC lookup: Extracted compound channel numbers: {channel_numbers}")
        else:
            # Look for standalone channel number
            channel_num_match = re.search(r"\b(\d{1,2})\b", channel_name)
            if channel_num_match:
                channel_numbers.append(int(channel_num_match.group(1)))

        # Get network from tags
        network = next(iter(network_tags), None) if network_tags else None

        # Try to find location in tags (non-network, non-quality tags that could be city names)
        # Filter out known non-location tags
        quality_tags = {"HD", "SD", "4K", "UHD", "FHD", "RAW", "60FPS", "30FPS", "HEVC", "H264", "H265"}
        country_tags = {"US", "USA", "UK", "CA", "AU", "DE", "FR", "ES", "IT", "MX", "BR", "JP"}
        network_set = {"ABC", "NBC", "CBS", "FOX", "PBS", "CW", "ION", "MY", "ME", "MYTV", "METV"}

        potential_locations = channel_tags - quality_tags - country_tags - network_set
        # Also filter out numeric-only tags and very short tags
        potential_locations = {t for t in potential_locations if len(t) >= 3 and not t.isdigit()}

        # Convert underscores to spaces in location tags (tags like "LAS_VEGAS" â†’ "LAS VEGAS")
        # This is needed because tags often store multi-word locations with underscores
        potential_locations = {t.replace("_", " ") for t in potential_locations}

        # For multi-word locations (e.g., "HAMPTON ROADS", "LAS VEGAS"), also try:
        # 1. Individual words (for cases like "HAMPTON ROADS" where city is just "HAMPTON")
        # 2. The full phrase (for cases like "LAS VEGAS" where city is "LAS VEGAS")
        expanded_locations: Set[str] = set()
        for loc in potential_locations:
            expanded_locations.add(loc)  # Add the full location
            words = loc.split()
            if len(words) > 1:
                # Add individual words that are long enough to be city names
                for word in words:
                    if len(word) >= 4:  # Skip short words like "OF", "THE", etc.
                        expanded_locations.add(word)
        potential_locations = expanded_locations

        # Try to extract callsign from channel name (e.g., "ABC 3 WSIL" -> "WSIL")
        # US broadcast callsigns are 3-4 letters starting with K (west) or W (east)
        potential_callsigns: Set[str] = set()
        callsign_pattern = re.compile(r"\b([KW][A-Z]{2,3}(?:-[A-Z]{2,3})?)\b", re.IGNORECASE)
        if channel_name:
            matches = callsign_pattern.findall(channel_name.upper())
            for match in matches:
                # Filter out network names that look like callsigns
                if match not in network_set and len(match) >= 3:
                    potential_callsigns.add(match)
                    logger.debug(f"FCC lookup: Extracted potential callsign from name: {match}")

        # Also check tags for callsign-like patterns (e.g., WMAR, KABC)
        for tag in channel_tags:
            if callsign_pattern.match(tag) and tag not in network_set:
                potential_callsigns.add(tag)

        # If no location tags found, try to extract city name from channel name
        # Look for words at the end of the name that could be city names
        # e.g., "ABC 13 Asheville" -> "Asheville"
        if not potential_locations and channel_name:
            # Remove network and numbers from name to isolate potential city
            name_for_city = channel_name.upper()
            # Remove network names
            for net in network_set:
                name_for_city = re.sub(rf"\b{net}\b", "", name_for_city)
            # Remove numbers
            name_for_city = re.sub(r"\b\d+\b", "", name_for_city)
            # Remove quality tags
            for qt in quality_tags:
                name_for_city = re.sub(rf"\b{qt}\b", "", name_for_city)
            # Remove potential callsigns (we handle those separately)
            for cs in potential_callsigns:
                name_for_city = re.sub(rf"\b{re.escape(cs)}\b", "", name_for_city)
            # Clean up and get remaining words
            remaining_words = [w.strip() for w in name_for_city.split() if len(w.strip()) >= 3]
            if remaining_words:
                # Add these as potential locations to try
                potential_locations = set(remaining_words)
                logger.debug(f"FCC lookup: Extracted potential cities from name: {potential_locations}")

        # Helper function to try FCC lookup with given parameters
        # This uses FccFacilityService to apply corrections before filtering
        def try_fcc_lookup(
            location: Optional[str],
            with_channel: bool,
            use_dma: bool = False,
            allow_independent: bool = False,
            channel_num: Optional[int] = None,
        ) -> Optional[str]:
            from services.fcc_facility_service import FccFacilityService

            if location:
                if use_dma:
                    # Search by Nielsen DMA (Designated Market Area) instead of city
                    query = FccFacility.query.filter(FccFacility.nielsen_dma.ilike(f"%{location}%"))
                else:
                    # Search by community_city (the city where the station is licensed)
                    query = FccFacility.query.filter(FccFacility.community_city.ilike(f"%{location}%"))
            else:
                # No location filter - used for callsign-only searches
                query = FccFacility.query

            if with_channel and channel_num is not None:
                # Match by virtual channel (what viewers see) preferentially
                query = query.filter(
                    db.or_(
                        FccFacility.tv_virtual_channel == str(channel_num),
                        FccFacility.channel == str(channel_num),
                    )
                )

            # Get all facilities matching location/channel criteria and apply corrections
            facilities = FccFacilityService.query_with_corrections(query)

            # Now filter by network affiliation (after corrections are applied)
            if allow_independent:
                # Accept INDEPENDENT or blank network affiliation
                facilities = [
                    f
                    for f in facilities
                    if not f.network_affiliation or f.network_affiliation.upper() in ("", "INDEPENDENT")
                ]
            elif network:
                # Filter by network (case-insensitive contains)
                network_upper = network.upper()
                facilities = [
                    f for f in facilities if f.network_affiliation and network_upper in f.network_affiliation.upper()
                ]

            if len(facilities) == 1:
                return facilities[0].callsign
            elif len(facilities) > 1:
                # Multiple matches - if all have same callsign, use it
                callsigns = {f.callsign for f in facilities}
                if len(callsigns) == 1:
                    return callsigns.pop()
            return None

        # Strategy 1: Try to match by callsign extracted from name/tags first
        # This is the most reliable method when a callsign is present
        from services.fcc_facility_service import FccFacilityService

        for callsign in potential_callsigns:
            # Check if this callsign exists in FCC data (with corrections applied)
            query = FccFacility.query.filter(FccFacility.callsign.ilike(f"{callsign}%"))
            facility = FccFacilityService.first_with_correction(query)
            if facility:
                logger.debug(f"FCC lookup: Direct callsign match for {callsign}: {facility.callsign}")
                return facility.callsign

        # Strategy 2: Try each potential location with network + channel number
        for location in potential_locations:
            # First try with channel number for precision (if we have any)
            # For compound channels like "33/40", try each number independently
            for ch_num in channel_numbers:
                result = try_fcc_lookup(location, with_channel=True, channel_num=ch_num)
                if result:
                    logger.debug(
                        f"FCC lookup: Found match for location={location}, "
                        f"network={network}, channel={ch_num}: {result}"
                    )
                    return result

            # Fall back to matching by location + network without channel number
            # This is useful because IPTV channel numbers often don't match FCC RF channels
            if network:
                result = try_fcc_lookup(location, with_channel=False)
                if result:
                    logger.debug(
                        f"FCC lookup: Found match for location={location}, "
                        f"network={network} (no channel filter): {result}"
                    )
                    return result

        # Strategy 3: Try searching by Nielsen DMA (Designated Market Area)
        # This handles cases like Raleigh where the ABC affiliate (WTVD) is licensed to Durham
        # but serves the "Raleigh-Durham" DMA
        if network:
            for location in potential_locations:
                result = try_fcc_lookup(location, with_channel=False, use_dma=True)
                if result:
                    logger.debug(
                        f"FCC lookup: Found match via DMA for location={location}, " f"network={network}: {result}"
                    )
                    return result

        # Strategy 4: If no network match found, try INDEPENDENT/blank affiliations
        # when we have a channel number match (for stations with missing affiliation data)
        if channel_numbers and potential_locations:
            for location in potential_locations:
                for ch_num in channel_numbers:
                    result = try_fcc_lookup(location, with_channel=True, allow_independent=True, channel_num=ch_num)
                    if result:
                        logger.debug(
                            f"FCC lookup: Found independent station for location={location}, "
                            f"channel={ch_num}: {result}"
                        )
                        return result

        return None

    @staticmethod
    def match_channels_to_epg(
        account_id: int,
        source_id: Optional[int] = None,
        category_id: Optional[int] = None,
        skip_matched_threshold: float = 0.85,
        batch_size: int = 100,
    ) -> Dict:
        """
        Attempt to match channels from an account to EPG channels.

        Matching strategies:
        1. Exact match on epg_channel_id (provider-assigned)
        2. Callsign tag match (matches channel's callsign tags to EPG channel IDs)
        3. FCC lookup (uses city, network, channel number to find callsign)
        4. Exact match on cleaned channel name
        5. Fuzzy match on channel name

        Args:
            account_id: Account to match channels for
            source_id: Optional - limit to specific EPG source
            category_id: Optional - limit to channels in specific category
            skip_matched_threshold: Skip channels with existing match at or above
                                    this confidence (default 0.85)
            batch_size: Number of channels to process before committing (default 100)

        Returns:
            Dict with matching statistics
        """
        stats = {
            "total_channels": 0,
            "skipped_existing": 0,
            "matched_exact_id": 0,
            "matched_callsign_tag": 0,
            "matched_fcc_lookup": 0,
            "matched_exact_name": 0,
            "matched_fuzzy": 0,
            "unmatched": 0,
        }

        # Get channels for this account, optionally filtered by category
        query = Channel.query.filter_by(account_id=account_id, is_active=True)
        if category_id:
            query = query.filter_by(category_id=category_id)
        channels = query.all()

        stats["total_channels"] = len(channels)
        filter_desc = ""
        if category_id:
            filter_desc = f" in category {category_id}"
        logger.info(f"EPG matching: Found {len(channels)} active channels{filter_desc} for account {account_id}")

        # Get all EPG channels
        epg_query = EpgChannel.query
        if source_id:
            epg_query = epg_query.filter_by(source_id=source_id)
        epg_channels = epg_query.all()
        logger.info(
            f"EPG matching: Found {len(epg_channels)} EPG channels{f' for source {source_id}' if source_id else ''}"
        )

        # Build lookup indices
        epg_by_id = {ec.channel_id.lower(): ec for ec in epg_channels}
        logger.debug(f"EPG matching: Built index with {len(epg_by_id)} unique EPG channel IDs")
        epg_by_name = {}
        for ec in epg_channels:
            # Index by all display names
            names = [ec.display_name.lower()] if ec.display_name else []
            if ec.display_names_json:
                try:
                    names.extend([n.lower() for n in json.loads(ec.display_names_json)])
                except (json.JSONDecodeError, TypeError):
                    pass
            for name in names:
                normalized = EpgService._normalize_name(name)
                if normalized:
                    epg_by_name[normalized] = ec

        # Build callsign index for EPG channels (maps callsigns like "WCTI" to EPG channels)
        epg_by_callsign = EpgService._build_callsign_epg_index(epg_channels)
        logger.debug(f"EPG matching: Built callsign index with {len(epg_by_callsign)} entries")

        # Get existing mappings to avoid duplicates
        # Batch the query to avoid SQLite's "too many SQL variables" error
        # SQLite has a limit (typically 999 or 32766) on bind parameters
        BATCH_SIZE = 500
        existing_mappings: Dict[int, ChannelEpgMapping] = {}
        channel_ids = [c.id for c in channels]
        for i in range(0, len(channel_ids), BATCH_SIZE):
            batch = channel_ids[i : i + BATCH_SIZE]
            for m in ChannelEpgMapping.query.filter(ChannelEpgMapping.channel_id.in_(batch)).all():
                existing_mappings[m.channel_id] = m

        # Pre-load ALL tags for all channels in batches for efficiency
        # This includes country tags for filtering and callsign tags for matching
        stream_ids = [c.stream_id for c in channels]
        all_tags_by_stream: Dict[str, Set[str]] = {}
        country_tags_by_stream: Dict[str, Set[str]] = {}
        callsign_tags_by_stream: Dict[str, Set[str]] = {}

        for i in range(0, len(stream_ids), BATCH_SIZE):
            batch = stream_ids[i : i + BATCH_SIZE]
            tag_rows = (
                db.session.query(ChannelTag.stream_id, Tag.name)
                .join(Tag, Tag.id == ChannelTag.tag_id)
                .filter(ChannelTag.account_id == account_id, ChannelTag.stream_id.in_(batch))
                .all()
            )
            for stream_id, tag_name in tag_rows:
                tag_upper = tag_name.upper()

                # Store all tags
                if stream_id not in all_tags_by_stream:
                    all_tags_by_stream[stream_id] = set()
                all_tags_by_stream[stream_id].add(tag_upper)

                # Track country tags separately
                if tag_upper in COUNTRY_TAG_TO_SUFFIX:
                    if stream_id not in country_tags_by_stream:
                        country_tags_by_stream[stream_id] = set()
                    country_tags_by_stream[stream_id].add(tag_upper)

                # Track callsign tags (K/W prefix, 3-6 alphanumeric chars)
                if len(tag_upper) >= 3 and len(tag_upper) <= 6 and tag_upper[0] in ("K", "W") and tag_upper.isalnum():
                    if stream_id not in callsign_tags_by_stream:
                        callsign_tags_by_stream[stream_id] = set()
                    callsign_tags_by_stream[stream_id].add(tag_upper)

        logger.debug(
            f"EPG matching: Loaded tags for {len(all_tags_by_stream)} channels, "
            f"{len(callsign_tags_by_stream)} with callsign tags"
        )

        # Process channels in batches for better performance and incremental saves
        channels_processed = 0

        for channel in channels:
            # Skip if already has a manual override mapping
            if channel.id in existing_mappings:
                existing = existing_mappings[channel.id]
                if existing.is_override:
                    stats["skipped_existing"] += 1
                    continue
                # Skip if existing match is good enough
                if existing.confidence and existing.confidence >= skip_matched_threshold:
                    stats["skipped_existing"] += 1
                    continue

            matched_epg = None
            match_type = None
            confidence = 0.0

            # Get country tags for this channel
            channel_country_tags = country_tags_by_stream.get(channel.stream_id, set())

            # Strategy 1: Exact match on epg_channel_id from provider
            # Skip obviously bad/placeholder EPG IDs (too short or generic)
            if channel.epg_channel_id and len(channel.epg_channel_id) > 3:
                epg_id_lower = channel.epg_channel_id.lower()
                if epg_id_lower in epg_by_id:
                    matched_epg = epg_by_id[epg_id_lower]
                    match_type = "provider"
                    confidence = 1.0
                    stats["matched_exact_id"] += 1

            # Strategy 2: Callsign tag match (for US broadcast stations)
            # Match channel's callsign tags (e.g., "WCTI") to EPG channel IDs (e.g., "WCTI-DT.us")
            if not matched_epg and "US" in channel_country_tags:
                channel_callsign_tags = callsign_tags_by_stream.get(channel.stream_id, set())
                for callsign_tag in channel_callsign_tags:
                    if callsign_tag in epg_by_callsign:
                        matched_epg = epg_by_callsign[callsign_tag]
                        match_type = "callsign_tag"
                        confidence = 0.97  # High confidence for callsign match
                        stats["matched_callsign_tag"] += 1
                        logger.debug(
                            f"EPG match via callsign tag: '{channel.name}' -> "
                            f"'{matched_epg.display_name}' (tag={callsign_tag})"
                        )
                        break

            # Strategy 3: FCC lookup (for US broadcast stations without callsign tag)
            # Use city/location tags, network tags, and channel number to find callsign in FCC data
            if not matched_epg and "US" in channel_country_tags:
                channel_all_tags = all_tags_by_stream.get(channel.stream_id, set())
                # Find network tags for this channel
                channel_network_tags = channel_all_tags & MAJOR_BROADCAST_NETWORKS
                if channel_network_tags:
                    # Try FCC lookup
                    fcc_callsign = EpgService._lookup_fcc_callsign(
                        channel.cleaned_name or channel.name,
                        channel_all_tags,
                        channel_network_tags,
                    )
                    if fcc_callsign:
                        fcc_upper = fcc_callsign.upper()
                        # Try exact FCC callsign first
                        if fcc_upper in epg_by_callsign:
                            matched_epg = epg_by_callsign[fcc_upper]
                        else:
                            # Strip suffix (-TV, -DT, etc.) and try base callsign
                            # FCC uses -TV suffix, EPG often uses -DT
                            base_callsign = re.sub(
                                r"-(DT|TV|HD|CD|LP|FM|DT2?|TV2?)$", "", fcc_upper, flags=re.IGNORECASE
                            )
                            if base_callsign in epg_by_callsign:
                                matched_epg = epg_by_callsign[base_callsign]

                        if matched_epg:
                            match_type = "fcc_lookup"
                            confidence = 0.93  # High confidence but slightly less than direct callsign tag
                            stats["matched_fcc_lookup"] += 1
                            logger.debug(
                                f"EPG match via FCC lookup: '{channel.name}' -> "
                                f"'{matched_epg.display_name}' (callsign={fcc_callsign})"
                            )

            # Strategy 4: Exact match on cleaned name
            if not matched_epg and channel.cleaned_name:
                normalized = EpgService._normalize_name(channel.cleaned_name)
                if normalized and normalized in epg_by_name:
                    matched_epg = epg_by_name[normalized]
                    match_type = "auto_exact"
                    confidence = 0.95
                    stats["matched_exact_name"] += 1

            # Strategy 5: Fuzzy match (includes token matching, contains, country filtering, etc.)
            if not matched_epg:
                best_match, best_score = EpgService._fuzzy_match(
                    channel.cleaned_name or channel.name,
                    epg_channels,
                    country_tags=channel_country_tags if channel_country_tags else None,
                )
                if best_match and best_score >= 0.75:
                    matched_epg = best_match
                    match_type = "auto_fuzzy"
                    confidence = best_score
                    stats["matched_fuzzy"] += 1

            if matched_epg and match_type:
                # Create or update mapping
                if channel.id in existing_mappings:
                    mapping = existing_mappings[channel.id]
                    if not mapping.is_override:  # Don't overwrite manual mappings
                        mapping.epg_channel_id = matched_epg.id
                        mapping.mapping_type = match_type
                        mapping.confidence = confidence
                        mapping.updated_at = datetime.utcnow()
                else:
                    mapping = ChannelEpgMapping(
                        channel_id=channel.id,
                        epg_channel_id=matched_epg.id,
                        mapping_type=match_type,
                        confidence=confidence,
                    )
                    db.session.add(mapping)
            else:
                stats["unmatched"] += 1

            # Commit in batches
            channels_processed += 1
            if channels_processed % batch_size == 0:
                db.session.commit()
                logger.debug(f"EPG matching: Processed {channels_processed}/{len(channels)} channels")

        # Final commit for any remaining
        db.session.commit()

        logger.info(
            f"EPG matching for account {account_id}{filter_desc}: "
            f"skipped={stats['skipped_existing']}, exact_id={stats['matched_exact_id']}, "
            f"callsign_tag={stats['matched_callsign_tag']}, fcc_lookup={stats['matched_fcc_lookup']}, "
            f"exact_name={stats['matched_exact_name']}, fuzzy={stats['matched_fuzzy']}, "
            f"unmatched={stats['unmatched']}"
        )

        return stats

    @staticmethod
    def _normalize_name(name: str) -> str:
        """Normalize a channel name for matching"""
        if not name:
            return ""
        # Lowercase, keep only ASCII alphanumeric and spaces, collapse whitespace
        name = name.lower()
        # Only keep a-z, 0-9, and spaces (removes all Unicode special chars)
        name = re.sub(r"[^a-z0-9\s]", "", name)
        name = re.sub(r"\s+", " ", name).strip()
        return name

    @staticmethod
    def _extract_country_from_epg_id(epg_channel_id: str) -> Optional[str]:
        """
        Extract country code from EPG channel ID.

        Common patterns:
        - "ESPN.us" -> "US"
        - "Court.TV.us2" -> "US"
        - "BBC1.uk" -> "UK"
        - "RTL.de" -> "DE"

        Returns:
            Uppercase country code or None
        """
        if not epg_channel_id:
            return None

        channel_id_lower = epg_channel_id.lower()

        # Check for known country suffixes
        for country_tag, suffixes in COUNTRY_TAG_TO_SUFFIX.items():
            for suffix in suffixes:
                if channel_id_lower.endswith(suffix):
                    return country_tag

        # Try to extract 2-letter suffix after last dot
        if "." in epg_channel_id:
            last_part = epg_channel_id.split(".")[-1].lower()
            # Remove trailing numbers (e.g., "us2" -> "us")
            country_part = re.sub(r"\d+$", "", last_part)
            if len(country_part) == 2 and country_part.isalpha():
                return country_part.upper()

        return None

    @staticmethod
    def _get_channel_country_tags(account_id: int, stream_id: str) -> Set[str]:
        """
        Get country-related tags for a channel.

        Returns:
            Set of uppercase country codes found in channel's tags
        """
        # Query tags for this channel
        tag_names = (
            db.session.query(Tag.name)
            .join(ChannelTag, Tag.id == ChannelTag.tag_id)
            .filter(ChannelTag.account_id == account_id, ChannelTag.stream_id == stream_id)
            .all()
        )

        # Filter to just country codes
        country_codes = set()
        for (tag_name,) in tag_names:
            tag_upper = tag_name.upper()
            if tag_upper in COUNTRY_TAG_TO_SUFFIX:
                country_codes.add(tag_upper)

        return country_codes

    # Common suffixes/prefixes to strip when trying variations
    # These are quality/region markers that don't affect channel identity
    STRIP_WORDS = {
        "hd",
        "sd",
        "fhd",
        "uhd",
        "4k",
        "8k",
        "the",
        "channel",
        "channels",
        "tv",
        "network",
        "networks",
        "television",
        "us",
        "uk",
        "ca",
        "au",
        "de",
        "fr",
        "es",
        "it",
        "east",
        "west",
        "pacific",
        "central",
        "plus",
        "extra",
        "max",
        "international",
        "world",
        "global",
    }

    @staticmethod
    def _get_name_tokens(name: str) -> Set[str]:
        """Extract meaningful tokens from a channel name for matching"""
        if not name:
            return set()

        normalized = EpgService._normalize_name(name)
        if not normalized:
            return set()

        # Split into words and filter out common noise words
        tokens = set(normalized.split())
        # Keep tokens that are either not noise or are the only token
        meaningful = {t for t in tokens if t not in EpgService.STRIP_WORDS or len(tokens) == 1}
        return meaningful if meaningful else tokens

    @staticmethod
    def _get_name_variations(name: str) -> List[str]:
        """
        Generate variations of a name by stripping common suffixes/prefixes.
        Returns list of variations to try, most specific first.
        """
        if not name:
            return []

        normalized = EpgService._normalize_name(name)
        if not normalized:
            return []

        variations = [normalized]
        words = normalized.split()

        if len(words) <= 1:
            return variations

        # Try stripping from the end
        for i in range(len(words) - 1, 0, -1):
            if words[i] in EpgService.STRIP_WORDS:
                stripped = " ".join(words[:i])
                if stripped and stripped not in variations:
                    variations.append(stripped)
            else:
                break

        # Try stripping from the beginning
        for i in range(len(words) - 1):
            if words[i] in EpgService.STRIP_WORDS:
                stripped = " ".join(words[i + 1 :])
                if stripped and stripped not in variations:
                    variations.append(stripped)
            else:
                break

        # Try stripping both ends
        start = 0
        end = len(words)
        for i in range(len(words)):
            if words[i] in EpgService.STRIP_WORDS:
                start = i + 1
            else:
                break
        for i in range(len(words) - 1, -1, -1):
            if words[i] in EpgService.STRIP_WORDS:
                end = i
            else:
                break
        if start < end:
            stripped = " ".join(words[start:end])
            if stripped and stripped not in variations:
                variations.append(stripped)

        return variations

    @staticmethod
    def _calculate_match_score(channel_name: str, epg_name: str) -> Tuple[float, str]:
        """
        Calculate a match score between a channel name and EPG name.

        Returns:
            Tuple of (score 0-1, match_type string)
        """
        if not channel_name or not epg_name:
            return 0.0, "none"

        norm_channel = EpgService._normalize_name(channel_name)
        norm_epg = EpgService._normalize_name(epg_name)

        if not norm_channel or not norm_epg:
            return 0.0, "none"

        # Minimum length requirements to avoid spurious matches
        # Very short names like "A+", "E!" should only match exactly
        MIN_NAME_LENGTH = 3
        if len(norm_epg) < MIN_NAME_LENGTH or len(norm_channel) < MIN_NAME_LENGTH:
            if norm_channel == norm_epg:
                return 1.0, "exact"
            return 0.0, "none"

        # Strategy 1: Exact match after normalization
        if norm_channel == norm_epg:
            return 1.0, "exact"

        # Strategy 2: Try variations with stripped suffixes/prefixes for exact match
        channel_variations = EpgService._get_name_variations(channel_name)
        epg_variations = EpgService._get_name_variations(epg_name)

        for cv in channel_variations:
            for ev in epg_variations:
                if cv == ev and len(cv) >= MIN_NAME_LENGTH:
                    # Exact match after stripping - high confidence
                    return 0.95, "exact_stripped"

        # Strategy 3: Check for common abbreviation patterns
        # E.g., "BBC" should match "British Broadcasting Corporation"
        if len(norm_channel) <= 5 and len(norm_channel) >= 2 and norm_channel.isalpha():
            epg_words = norm_epg.split()
            if len(epg_words) >= len(norm_channel):
                initials = "".join(w[0] for w in epg_words[: len(norm_channel)])
                if initials == norm_channel:
                    return 0.90, "abbreviation"

        # Also check reverse: EPG is abbreviation of channel name
        if len(norm_epg) <= 5 and len(norm_epg) >= 2 and norm_epg.isalpha():
            channel_words = norm_channel.split()
            if len(channel_words) >= len(norm_epg):
                initials = "".join(w[0] for w in channel_words[: len(norm_epg)])
                if initials == norm_epg:
                    return 0.90, "abbreviation"

        # Strategy 4: One contains the other - but with stricter requirements
        MIN_CONTAINS_LENGTH = 5
        if len(norm_channel) >= MIN_CONTAINS_LENGTH and norm_channel in norm_epg:
            ratio = len(norm_channel) / len(norm_epg)
            # Only match if we cover at least 60% of the EPG name
            if ratio >= 0.6:
                score = 0.80 + (ratio * 0.15)  # 0.80 - 0.95
                return min(score, 0.95), "contains"

        if len(norm_epg) >= MIN_CONTAINS_LENGTH and norm_epg in norm_channel:
            ratio = len(norm_epg) / len(norm_channel)
            # Only match if EPG name covers at least 60% of channel name
            if ratio >= 0.6:
                score = 0.75 + (ratio * 0.15)  # 0.75 - 0.90
                return min(score, 0.90), "contains"

        # Strategy 5: Token-based matching with stricter requirements
        channel_tokens = EpgService._get_name_tokens(channel_name)
        epg_tokens = EpgService._get_name_tokens(epg_name)

        if channel_tokens and epg_tokens and len(channel_tokens) >= 1 and len(epg_tokens) >= 1:
            shorter, longer = (
                (channel_tokens, epg_tokens) if len(channel_tokens) <= len(epg_tokens) else (epg_tokens, channel_tokens)
            )

            matching_tokens = shorter & longer

            # Require ALL tokens from shorter to match AND substantial coverage
            if matching_tokens == shorter and len(shorter) >= 2:
                coverage = len(shorter) / len(longer)
                if coverage >= 0.5:
                    score = 0.80 + (coverage * 0.15)  # 0.80 - 0.95
                    return min(score, 0.95), "token_match"

            # Single meaningful token match - both names have just 1 token
            if len(matching_tokens) == 1 and len(shorter) == 1 and len(longer) == 1:
                return 0.90, "token_match"

        # Strategy 6: Fuzzy sequence matching (fallback) - stricter threshold
        # Only use fuzzy if names are similar lengths (within 2x of each other)
        length_ratio = min(len(norm_channel), len(norm_epg)) / max(len(norm_channel), len(norm_epg))
        if length_ratio < 0.5:
            # Names are too different in length - likely not a match
            return 0.0, "none"

        seq_score = SequenceMatcher(None, norm_channel, norm_epg).ratio()

        # Only return fuzzy scores above a high threshold (0.85)
        # This avoids false positives from partial word matches
        if seq_score >= 0.85:
            return seq_score, "fuzzy"

        return 0.0, "none"

    @staticmethod
    def _fuzzy_match(
        channel_name: str,
        epg_channels: List[EpgChannel],
        min_score: float = 0.75,
        country_tags: Optional[Set[str]] = None,
    ) -> Tuple[Optional[EpgChannel], float]:
        """
        Find the best fuzzy match for a channel name.

        Uses multiple matching strategies:
        1. Exact match after normalization
        2. Exact match with stripped suffixes (HD, Network, etc.)
        3. Abbreviation matching
        4. Contains/prefix matching (with stricter requirements)
        5. Token-based matching (all significant words match)
        6. Fuzzy sequence matching (high threshold)
        5. Abbreviation matching
        6. Country tag matching (boost/filter by country suffix in EPG channel ID)

        Args:
            channel_name: The channel name to match
            epg_channels: List of EPG channels to search
            min_score: Minimum similarity score (0-1), default 0.65
            country_tags: Optional set of country codes (e.g., {"US", "UK"}) to prefer

        Returns:
            Tuple of (best matching EpgChannel or None, score)
        """
        if not channel_name:
            return None, 0.0

        normalized_name = EpgService._normalize_name(channel_name)
        if not normalized_name:
            return None, 0.0

        # Track all candidates with their scores
        candidates: List[Tuple[EpgChannel, float, str, bool]] = []  # (epg, score, type, country_match)

        for ec in epg_channels:
            names_to_check = [ec.display_name] if ec.display_name else []
            if ec.display_names_json:
                try:
                    names_to_check.extend(json.loads(ec.display_names_json))
                except (json.JSONDecodeError, TypeError):
                    pass

            # Check if this EPG channel's country matches our tags
            epg_country = EpgService._extract_country_from_epg_id(ec.channel_id)
            country_match = bool(country_tags and epg_country and epg_country in country_tags)

            best_name_score = 0.0
            best_name_type = "none"

            for epg_name in names_to_check:
                if not epg_name:
                    continue

                score, match_type = EpgService._calculate_match_score(channel_name, epg_name)

                if score > best_name_score:
                    best_name_score = score
                    best_name_type = match_type

            if best_name_score >= min_score:
                candidates.append((ec, best_name_score, best_name_type, country_match))

        if not candidates:
            return None, 0.0

        # Sort candidates: first by country match (True first), then by score descending
        candidates.sort(key=lambda x: (x[3], x[1]), reverse=True)

        best_match, best_score, best_match_type, country_matched = candidates[0]

        # Log match details
        match_info = f"EPG match: '{channel_name}' -> '{best_match.display_name}' "
        match_info += f"(score={best_score:.2f}, type={best_match_type}"
        if country_matched:
            match_info += ", country_match=True"
        if len(candidates) > 1:
            match_info += f", {len(candidates)} candidates"
        match_info += ")"
        logger.debug(match_info)

        return best_match, best_score

    # =========================================================================
    # FCC-Enhanced EPG Matching
    # =========================================================================

    @staticmethod
    def _get_fcc_facility_for_channel(channel: Channel) -> Optional[FccFacility]:
        """
        Look up FCC facility data for a channel using its callsign.

        Extracts callsign from channel name (e.g., "US: NBC (WNBC)" -> WNBC)
        and looks up the corresponding FCC facility record.

        Args:
            channel: Channel to look up

        Returns:
            FccFacility record or None
        """
        from services.fcc_facility_service import FccFacilityService

        callsign = FccFacilityService.extract_callsign_from_name(channel.name)
        if not callsign:
            return None

        return FccFacilityService.lookup_by_callsign(callsign)

    @staticmethod
    def _match_by_fcc_callsign(
        channel: Channel,
        epg_by_callsign: Dict[str, EpgChannel],
        facility: Optional[FccFacility] = None,
    ) -> Optional[Tuple[EpgChannel, float, str]]:
        """
        Match a channel to EPG using FCC callsign data.

        EPG channels often use formats like "KABC.us" or "WNBC.us".
        This method matches using the FCC-verified callsign.

        Args:
            channel: Channel to match
            epg_by_callsign: Dict mapping callsigns to EPG channels
            facility: Optional pre-looked-up FCC facility

        Returns:
            Tuple of (EpgChannel, confidence, match_type) or None
        """
        if facility is None:
            facility = EpgService._get_fcc_facility_for_channel(channel)

        if not facility:
            return None

        # Try exact callsign match
        callsign_upper = facility.callsign.upper()
        if callsign_upper in epg_by_callsign:
            return (epg_by_callsign[callsign_upper], 0.98, "fcc_callsign")

        # Try without common suffixes (-TV, -DT, etc.)
        base_callsign = callsign_upper.split("-")[0]
        if base_callsign != callsign_upper and base_callsign in epg_by_callsign:
            return (epg_by_callsign[base_callsign], 0.95, "fcc_callsign_base")

        # Try with common suffixes added
        for suffix in ["", "TV", "DT"]:
            test_callsign = f"{base_callsign}{suffix}" if suffix else base_callsign
            if test_callsign in epg_by_callsign:
                return (epg_by_callsign[test_callsign], 0.93, "fcc_callsign_variant")

        return None

    @staticmethod
    def _match_by_fcc_network(
        channel: Channel,
        epg_by_name: Dict[str, EpgChannel],
        facility: Optional[FccFacility] = None,
    ) -> Optional[Tuple[EpgChannel, float, str]]:
        """
        Match a channel to EPG using FCC network affiliation as fallback.

        When a local station doesn't have station-specific EPG, we can
        fall back to generic network EPG (e.g., CBS affiliate -> CBS EPG).
        This is lower confidence as programming may differ.

        Args:
            channel: Channel to match
            epg_by_name: Dict mapping normalized names to EPG channels
            facility: Optional pre-looked-up FCC facility

        Returns:
            Tuple of (EpgChannel, confidence, match_type) or None
        """
        if facility is None:
            facility = EpgService._get_fcc_facility_for_channel(channel)

        if not facility or not facility.network_affiliation:
            return None

        network = facility.network_affiliation.upper()

        # Only use network fallback for major broadcast networks
        if network not in MAJOR_BROADCAST_NETWORKS:
            return None

        # Try to find network EPG channel
        network_normalized = EpgService._normalize_name(network)
        if network_normalized in epg_by_name:
            # Lower confidence since this is a fallback, not exact station match
            return (epg_by_name[network_normalized], 0.60, "fcc_network_fallback")

        return None

    @staticmethod
    def _build_fcc_epg_indices(
        epg_channels: List[EpgChannel],
    ) -> Tuple[Dict[str, EpgChannel], Dict[str, List[EpgChannel]]]:
        """
        Build lookup indices for FCC-enhanced EPG matching.

        Creates:
        1. Callsign index: Maps callsigns (extracted from EPG channel IDs) to EPG channels
        2. DMA/Market index: Maps market names to EPG channels in that market

        Args:
            epg_channels: List of EPG channels to index

        Returns:
            Tuple of (callsign_dict, dma_dict)
        """
        epg_by_callsign: Dict[str, EpgChannel] = {}
        epg_by_dma: Dict[str, List[EpgChannel]] = {}

        for ec in epg_channels:
            # Extract callsign from channel_id (e.g., "KABC.us" -> "KABC")
            callsign = extract_callsign_from_xmltv_id(ec.channel_id)
            if callsign:
                # Only index if it looks like a broadcast callsign (starts with K or W)
                callsign_upper = callsign.upper()
                if len(callsign_upper) >= 3 and callsign_upper[0] in ("K", "W"):
                    epg_by_callsign[callsign_upper] = ec

                # Also try display name as callsign
                if ec.display_name:
                    display_upper = ec.display_name.upper().strip()
                    if len(display_upper) >= 3 and len(display_upper) <= 10:
                        if display_upper[0] in ("K", "W") and display_upper.replace("-", "").isalpha():
                            epg_by_callsign[display_upper] = ec

        return epg_by_callsign, epg_by_dma

    @staticmethod
    def match_channels_to_epg_fcc_enhanced(
        account_id: int,
        source_id: Optional[int] = None,
        category_id: Optional[int] = None,
        skip_matched_threshold: float = 0.85,
        batch_size: int = 100,
        use_network_fallback: bool = True,
    ) -> Dict:
        """
        Match channels to EPG using FCC data for enhanced accuracy.

        This enhanced matcher adds FCC-based matching strategies:
        1. Exact match on provider epg_channel_id (highest priority)
        2. FCC callsign match (matches extracted callsign to EPG like "KABC.us")
        3. Exact match on cleaned channel name
        4. Fuzzy match on channel name
        5. FCC network fallback (optional - uses network EPG for unmatched affiliates)

        For US broadcast stations, this significantly improves matching accuracy
        by using authoritative FCC callsign data rather than fuzzy name matching.

        Args:
            account_id: Account to match channels for
            source_id: Optional - limit to specific EPG source
            category_id: Optional - limit to channels in specific category
            skip_matched_threshold: Skip channels with existing match at or above
                                    this confidence (default 0.85)
            batch_size: Number of channels to process before committing
            use_network_fallback: Whether to use network fallback for unmatched
                                  broadcast affiliates (default True)

        Returns:
            Dict with matching statistics including FCC-specific counts
        """
        stats = {
            "total_channels": 0,
            "skipped_existing": 0,
            "matched_exact_id": 0,
            "matched_fcc_callsign": 0,
            "matched_exact_name": 0,
            "matched_fuzzy": 0,
            "matched_network_fallback": 0,
            "unmatched": 0,
        }

        # Get channels for this account, optionally filtered by category
        query = Channel.query.filter_by(account_id=account_id, is_active=True)
        if category_id:
            query = query.filter_by(category_id=category_id)
        channels = query.all()

        stats["total_channels"] = len(channels)
        filter_desc = ""
        if category_id:
            filter_desc = f" in category {category_id}"
        logger.info(
            f"EPG matching (FCC-enhanced): Found {len(channels)} active channels{filter_desc} "
            f"for account {account_id}"
        )

        # Get all EPG channels
        epg_query = EpgChannel.query
        if source_id:
            epg_query = epg_query.filter_by(source_id=source_id)
        epg_channels = epg_query.all()
        logger.info(
            f"EPG matching: Found {len(epg_channels)} EPG channels" f"{f' for source {source_id}' if source_id else ''}"
        )

        # Build lookup indices
        epg_by_id = {ec.channel_id.lower(): ec for ec in epg_channels}
        epg_by_name: Dict[str, EpgChannel] = {}
        for ec in epg_channels:
            # Index by all display names
            names = [ec.display_name.lower()] if ec.display_name else []
            if ec.display_names_json:
                try:
                    names.extend([n.lower() for n in json.loads(ec.display_names_json)])
                except (json.JSONDecodeError, TypeError):
                    pass
            for name in names:
                normalized = EpgService._normalize_name(name)
                if normalized:
                    epg_by_name[normalized] = ec

        # Build FCC-specific indices
        epg_by_callsign, epg_by_dma = EpgService._build_fcc_epg_indices(epg_channels)
        logger.debug(f"EPG matching: Built FCC callsign index with {len(epg_by_callsign)} entries")

        # Get existing mappings to avoid duplicates
        BATCH_SIZE = 500
        existing_mappings: Dict[int, ChannelEpgMapping] = {}
        channel_ids = [c.id for c in channels]
        for i in range(0, len(channel_ids), BATCH_SIZE):
            batch = channel_ids[i : i + BATCH_SIZE]
            for m in ChannelEpgMapping.query.filter(ChannelEpgMapping.channel_id.in_(batch)).all():
                existing_mappings[m.channel_id] = m

        # Pre-load country tags for all channels in batches
        stream_ids = [c.stream_id for c in channels]
        country_tags_by_stream: Dict[str, Set[str]] = {}

        for i in range(0, len(stream_ids), BATCH_SIZE):
            batch = stream_ids[i : i + BATCH_SIZE]
            tag_rows = (
                db.session.query(ChannelTag.stream_id, Tag.name)
                .join(Tag, Tag.id == ChannelTag.tag_id)
                .filter(ChannelTag.account_id == account_id, ChannelTag.stream_id.in_(batch))
                .all()
            )
            for stream_id, tag_name in tag_rows:
                tag_upper = tag_name.upper()
                if tag_upper in COUNTRY_TAG_TO_SUFFIX:
                    if stream_id not in country_tags_by_stream:
                        country_tags_by_stream[stream_id] = set()
                    country_tags_by_stream[stream_id].add(tag_upper)

        # Pre-load FCC facilities for US channels (batch lookup for efficiency)
        fcc_facilities_by_channel: Dict[int, Optional[FccFacility]] = {}
        us_channel_ids = [c.id for c in channels if country_tags_by_stream.get(c.stream_id, set()) & {"US"}]
        for channel in channels:
            if channel.id in us_channel_ids:
                fcc_facilities_by_channel[channel.id] = EpgService._get_fcc_facility_for_channel(channel)
            else:
                fcc_facilities_by_channel[channel.id] = None

        logger.debug(
            f"EPG matching: Pre-loaded FCC data for {sum(1 for v in fcc_facilities_by_channel.values() if v)} channels"
        )

        channels_processed = 0

        for channel in channels:
            # Skip if already has a manual override mapping
            if channel.id in existing_mappings:
                existing = existing_mappings[channel.id]
                if existing.is_override:
                    stats["skipped_existing"] += 1
                    continue
                if existing.confidence and existing.confidence >= skip_matched_threshold:
                    stats["skipped_existing"] += 1
                    continue

            matched_epg = None
            match_type = None
            confidence = 0.0

            channel_country_tags = country_tags_by_stream.get(channel.stream_id, set())
            facility = fcc_facilities_by_channel.get(channel.id)

            # Strategy 1: Exact match on epg_channel_id from provider
            if channel.epg_channel_id and len(channel.epg_channel_id) > 3:
                epg_id_lower = channel.epg_channel_id.lower()
                if epg_id_lower in epg_by_id:
                    matched_epg = epg_by_id[epg_id_lower]
                    match_type = "provider"
                    confidence = 1.0
                    stats["matched_exact_id"] += 1

            # Strategy 2: FCC callsign match (for US channels only)
            if not matched_epg and "US" in channel_country_tags and facility:
                fcc_match = EpgService._match_by_fcc_callsign(channel, epg_by_callsign, facility)
                if fcc_match:
                    matched_epg, confidence, match_type = fcc_match
                    stats["matched_fcc_callsign"] += 1
                    logger.debug(
                        f"FCC callsign match: '{channel.name}' -> '{matched_epg.display_name}' "
                        f"via callsign {facility.callsign}"
                    )

            # Strategy 3: Exact match on cleaned name
            if not matched_epg and channel.cleaned_name:
                normalized = EpgService._normalize_name(channel.cleaned_name)
                if normalized and normalized in epg_by_name:
                    matched_epg = epg_by_name[normalized]
                    match_type = "auto_exact"
                    confidence = 0.95
                    stats["matched_exact_name"] += 1

            # Strategy 4: Fuzzy match
            if not matched_epg:
                best_match, best_score = EpgService._fuzzy_match(
                    channel.cleaned_name or channel.name,
                    epg_channels,
                    country_tags=channel_country_tags if channel_country_tags else None,
                )
                if best_match and best_score >= 0.75:
                    matched_epg = best_match
                    match_type = "auto_fuzzy"
                    confidence = best_score
                    stats["matched_fuzzy"] += 1

            # Strategy 5: FCC network fallback (optional, lower priority)
            if not matched_epg and use_network_fallback and "US" in channel_country_tags and facility:
                network_match = EpgService._match_by_fcc_network(channel, epg_by_name, facility)
                if network_match:
                    matched_epg, confidence, match_type = network_match
                    stats["matched_network_fallback"] += 1
                    logger.debug(
                        f"FCC network fallback: '{channel.name}' -> '{matched_epg.display_name}' "
                        f"via network {facility.network_affiliation}"
                    )

            if matched_epg and match_type:
                if channel.id in existing_mappings:
                    mapping = existing_mappings[channel.id]
                    if not mapping.is_override:
                        mapping.epg_channel_id = matched_epg.id
                        mapping.mapping_type = match_type
                        mapping.confidence = confidence
                        mapping.updated_at = datetime.utcnow()
                else:
                    mapping = ChannelEpgMapping(
                        channel_id=channel.id,
                        epg_channel_id=matched_epg.id,
                        mapping_type=match_type,
                        confidence=confidence,
                    )
                    db.session.add(mapping)
            else:
                stats["unmatched"] += 1

            channels_processed += 1
            if channels_processed % batch_size == 0:
                db.session.commit()
                logger.debug(f"EPG matching: Processed {channels_processed}/{len(channels)} channels")

        db.session.commit()

        logger.info(
            f"EPG matching (FCC-enhanced) for account {account_id}{filter_desc}: "
            f"skipped={stats['skipped_existing']}, exact_id={stats['matched_exact_id']}, "
            f"fcc_callsign={stats['matched_fcc_callsign']}, exact_name={stats['matched_exact_name']}, "
            f"fuzzy={stats['matched_fuzzy']}, network_fallback={stats['matched_network_fallback']}, "
            f"unmatched={stats['unmatched']}"
        )

        return stats

    @staticmethod
    def preview_fcc_epg_matches(
        account_id: int,
        source_id: Optional[int] = None,
        limit: int = 100,
    ) -> List[Dict]:
        """
        Preview potential FCC-based EPG matches without applying them.

        Useful for reviewing what matches would be made before committing.

        Args:
            account_id: Account to preview matches for
            source_id: Optional - limit to specific EPG source
            limit: Maximum number of matches to return

        Returns:
            List of dicts with match details
        """
        from services.fcc_facility_service import FccFacilityService

        results: List[Dict] = []

        # Get US-tagged channels without high-confidence EPG mappings
        us_tag = Tag.query.filter(Tag.name.ilike("US")).first()
        if not us_tag:
            return results

        us_channel_stream_ids = set(
            ct.stream_id for ct in ChannelTag.query.filter_by(account_id=account_id, tag_id=us_tag.id).all()
        )

        channels = (
            Channel.query.filter(
                Channel.account_id == account_id,
                Channel.stream_id.in_(us_channel_stream_ids),
                Channel.is_active == True,  # noqa: E712
            )
            .limit(limit * 2)
            .all()
        )

        # Get EPG channels
        epg_query = EpgChannel.query
        if source_id:
            epg_query = epg_query.filter_by(source_id=source_id)
        epg_channels = epg_query.all()

        # Build callsign index
        epg_by_callsign, _ = EpgService._build_fcc_epg_indices(epg_channels)

        for channel in channels:
            if len(results) >= limit:
                break

            facility = EpgService._get_fcc_facility_for_channel(channel)
            if not facility:
                continue

            fcc_match = EpgService._match_by_fcc_callsign(channel, epg_by_callsign, facility)
            if fcc_match:
                matched_epg, confidence, match_type = fcc_match
                results.append(
                    {
                        "channel_id": channel.id,
                        "channel_name": channel.name,
                        "cleaned_name": channel.cleaned_name,
                        "extracted_callsign": FccFacilityService.extract_callsign_from_name(channel.name),
                        "fcc_callsign": facility.callsign,
                        "fcc_city": facility.community_city,
                        "fcc_state": facility.community_state,
                        "fcc_network": facility.network_affiliation,
                        "fcc_dma": facility.nielsen_dma,
                        "epg_channel_id": matched_epg.channel_id,
                        "epg_display_name": matched_epg.display_name,
                        "confidence": confidence,
                        "match_type": match_type,
                    }
                )

        return results

    @staticmethod
    def get_epg_coverage_stats(account_id: Optional[int] = None) -> Dict:
        """
        Get EPG coverage statistics.

        Args:
            account_id: Optional - filter to specific account

        Returns:
            Dict with coverage statistics
        """
        # Count channels with EPG mappings
        mapping_query = db.session.query(ChannelEpgMapping.channel_id).distinct()

        if account_id:
            # Filter to channels from this account
            mapping_query = mapping_query.join(Channel, ChannelEpgMapping.channel_id == Channel.id).filter(
                Channel.account_id == account_id
            )

        mapped_count = mapping_query.count()

        # Count total channels
        channel_query = Channel.query.filter_by(is_active=True)
        if account_id:
            channel_query = channel_query.filter_by(account_id=account_id)
        total_count = channel_query.count()

        # Count channels with provider EPG IDs
        provider_epg_query = Channel.query.filter(
            Channel.is_active == True, Channel.epg_channel_id.isnot(None), Channel.epg_channel_id != ""  # noqa: E712
        )
        if account_id:
            provider_epg_query = provider_epg_query.filter_by(account_id=account_id)
        provider_epg_count = provider_epg_query.count()

        # Count EPG sources and channels
        epg_source_count = EpgSource.query.filter_by(enabled=True).count()
        epg_channel_count = EpgChannel.query.count()

        return {
            "total_channels": total_count,
            "channels_with_provider_epg_id": provider_epg_count,
            "channels_with_epg_mapping": mapped_count,
            "coverage_percent": round((mapped_count / total_count * 100), 1) if total_count > 0 else 0,
            "epg_sources": epg_source_count,
            "epg_channels_available": epg_channel_count,
        }

    @staticmethod
    def get_category_epg_coverage(account_id: int) -> List[Dict]:
        """
        Get EPG coverage broken down by category.

        Args:
            account_id: Account to get stats for

        Returns:
            List of dicts with category info and EPG coverage
        """
        from models import Category

        results = []

        categories = Category.query.filter_by(account_id=account_id).all()

        for category in categories:
            # Count total active channels in category
            total = Channel.query.filter_by(account_id=account_id, category_id=category.id, is_active=True).count()

            if total == 0:
                continue

            # Count channels with provider EPG ID
            with_provider_epg = Channel.query.filter(
                Channel.account_id == account_id,
                Channel.category_id == category.id,
                Channel.is_active == True,  # noqa: E712
                Channel.epg_channel_id.isnot(None),
                Channel.epg_channel_id != "",
            ).count()

            # Count channels with EPG mappings
            with_mapping = (
                db.session.query(Channel.id)
                .join(ChannelEpgMapping, Channel.id == ChannelEpgMapping.channel_id)
                .filter(
                    Channel.account_id == account_id,
                    Channel.category_id == category.id,
                    Channel.is_active == True,  # noqa: E712
                )
                .count()
            )

            results.append(
                {
                    "category_id": category.id,
                    "category_name": category.category_name,
                    "total_channels": total,
                    "with_provider_epg": with_provider_epg,
                    "with_epg_mapping": with_mapping,
                    "coverage_percent": round((with_mapping / total * 100), 1) if total > 0 else 0,
                }
            )

        return sorted(results, key=lambda x: x["category_name"])

    @staticmethod
    def create_provider_epg_source(account_id: int) -> EpgSource:
        """
        Create or get an EPG source for a provider account.

        Args:
            account_id: Account ID

        Returns:
            EpgSource instance
        """
        from models import Account

        account = Account.query.get_or_404(account_id)

        # Check if source already exists
        existing = EpgSource.query.filter_by(account_id=account_id, source_type="provider").first()

        if existing:
            return existing

        source = EpgSource(
            name=f"{account.name} (Provider)",
            source_type="provider",
            account_id=account_id,
            priority=50,  # Provider sources get medium priority
            enabled=True,
        )
        db.session.add(source)
        db.session.commit()

        return source

    @staticmethod
    def generate_filtered_epg(
        channel_epg_ids: List[str],
        xml_content: bytes,
        channel_link_map: Optional[Dict[str, Tuple[str, int]]] = None,
    ) -> bytes:
        """
        Generate filtered EPG XML containing only specified channels.

        Uses channel links for EPG fallback - if a channel has a link to a source
        channel, programmes from the source are copied with the specified time offset.

        Args:
            channel_epg_ids: List of EPG channel IDs to include
            xml_content: Source XMLTV XML content (may be gzipped)
            channel_link_map: Optional mapping of channel_epg_id -> (source_epg_id, time_offset_hours)
                              All EPG IDs should be lowercase.

        Returns:
            Filtered XMLTV XML as bytes
        """
        if not channel_epg_ids:
            # Return minimal valid XMLTV
            return b'<?xml version="1.0" encoding="UTF-8"?>\n<tv generator-info-name="iptv-proxy-v2"></tv>\n'

        # Build lookup set for fast channel matching
        requested_ids = set(epg_id.lower() for epg_id in channel_epg_ids if epg_id)

        # Use provided channel_link_map or empty dict
        if channel_link_map is None:
            channel_link_map = {}

        # Build reverse lookup: source_epg_id -> list of (target_epg_id, time_offset)
        source_to_targets: Dict[str, List[Tuple[str, int]]] = {}
        for target_id, (source_id, offset) in channel_link_map.items():
            if source_id not in source_to_targets:
                source_to_targets[source_id] = []
            source_to_targets[source_id].append((target_id, offset))

        # Decompress if needed
        stream = get_decompressing_stream(xml_content)

        try:
            # Build result XML
            root = ET.Element("tv")
            root.set("generator-info-name", "iptv-proxy-v2")

            # Track which channels we've found EPG for
            found_channel_ids: Set[str] = set()
            programmes_by_channel: Dict[str, List[ET.Element]] = {}

            # Parse source XMLTV
            context = ET.iterparse(stream, events=("end",))

            for event, elem in context:
                if elem.tag == "channel":
                    channel_id = elem.get("id", "").lower()
                    if channel_id in requested_ids:
                        # Copy channel element
                        new_channel = ET.SubElement(root, "channel")
                        new_channel.set("id", elem.get("id", ""))
                        for child in elem:
                            new_channel.append(_copy_element(child))
                        found_channel_ids.add(channel_id)

                    elem.clear()

                elif elem.tag == "programme":
                    channel_id = elem.get("channel", "").lower()

                    # Direct match
                    if channel_id in requested_ids:
                        if channel_id not in programmes_by_channel:
                            programmes_by_channel[channel_id] = []
                        programmes_by_channel[channel_id].append(_copy_element(elem))

                    # Check if this is a source channel for any linked channels
                    if channel_id in source_to_targets:
                        for target_id, time_offset in source_to_targets[channel_id]:
                            if target_id not in programmes_by_channel:
                                programmes_by_channel[target_id] = []
                            shifted_prog = _copy_element(elem)
                            # Apply time offset
                            shifted_prog.set("channel", target_id)
                            if time_offset != 0:
                                start = shifted_prog.get("start")
                                stop = shifted_prog.get("stop")
                                if start:
                                    shifted_prog.set("start", shift_xmltv_time(start, time_offset))
                                if stop:
                                    shifted_prog.set("stop", shift_xmltv_time(stop, time_offset))
                            programmes_by_channel[target_id].append(shifted_prog)

                    elem.clear()

            # Add linked channels that weren't in original EPG but got programmes from source
            for target_id in channel_link_map.keys():
                if target_id not in found_channel_ids and target_id in programmes_by_channel:
                    # Create a channel entry for this linked channel
                    new_channel = ET.SubElement(root, "channel")
                    new_channel.set("id", target_id)
                    display_name = ET.SubElement(new_channel, "display-name")
                    display_name.text = target_id  # Basic fallback name

            # Add all programme elements
            for channel_id in sorted(programmes_by_channel.keys()):
                for prog in programmes_by_channel[channel_id]:
                    root.append(prog)

        finally:
            stream.close()

        # Generate XML output
        return ET.tostring(root, encoding="unicode", xml_declaration=True).encode("utf-8")

    @staticmethod
    def _build_channel_link_map(channel_ids: List[int]) -> Dict[str, Tuple[str, int]]:
        """
        Build a mapping from channels to their linked source channels.

        For channels with a ChannelLink, returns their source channel's EPG ID
        and the time offset to apply.

        Args:
            channel_ids: List of channel IDs (db primary keys) to check

        Returns:
            Dict mapping channel_epg_id -> (source_epg_id, time_offset_hours)
            All EPG IDs are lowercase.
        """
        from models import ChannelLink

        if not channel_ids:
            return {}

        link_map: Dict[str, Tuple[str, int]] = {}

        # Query all links for the given channels
        links = (
            ChannelLink.query.filter(ChannelLink.channel_id.in_(channel_ids))
            .options(
                db.joinedload(ChannelLink.channel),
                db.joinedload(ChannelLink.source_channel),
            )
            .all()
        )

        for link in links:
            if link.channel and link.source_channel:
                channel_epg_id = link.channel.epg_channel_id
                source_epg_id = link.source_channel.epg_channel_id

                if channel_epg_id and source_epg_id:
                    link_map[channel_epg_id.lower()] = (source_epg_id.lower(), link.time_offset_hours)

        return link_map

    @staticmethod
    def generate_epg_for_channels(
        channels: List[Channel],
        account_xml_cache: Optional[Dict[int, bytes]] = None,
        use_channel_links: bool = True,
    ) -> bytes:
        """
        Generate EPG XML for a list of channels.

        Fetches XMLTV data from accounts and filters to only include
        the specified channels. Uses ChannelLink for fallback EPG sources.

        Args:
            channels: List of Channel objects to generate EPG for
            account_xml_cache: Optional pre-fetched XML content by account ID
            use_channel_links: Whether to use ChannelLink for fallback EPG

        Returns:
            XMLTV XML content as bytes
        """
        from services.iptv_service import IPTVService

        if not channels:
            return b'<?xml version="1.0" encoding="UTF-8"?>\n<tv generator-info-name="iptv-proxy-v2"></tv>\n'

        # Build channel link map if enabled
        channel_link_map: Dict[str, Tuple[str, int]] = {}
        if use_channel_links:
            channel_ids = [ch.id for ch in channels]
            channel_link_map = EpgService._build_channel_link_map(channel_ids)

        # Group channels by account
        channels_by_account: Dict[int, List[Channel]] = {}
        for ch in channels:
            if ch.account_id not in channels_by_account:
                channels_by_account[ch.account_id] = []
            channels_by_account[ch.account_id].append(ch)

        # Build combined EPG
        root = ET.Element("tv")
        root.set("generator-info-name", "iptv-proxy-v2")

        all_channel_elements: List[ET.Element] = []
        all_programme_elements: List[ET.Element] = []

        for account_id, account_channels in channels_by_account.items():
            # Get EPG channel IDs for this account's channels
            epg_ids = [ch.epg_channel_id for ch in account_channels if ch.epg_channel_id]

            if not epg_ids:
                continue

            # Get XMLTV content for this account
            xml_content = None
            if account_xml_cache and account_id in account_xml_cache:
                xml_content = account_xml_cache[account_id]
            else:
                # Fetch from account
                from models import Account

                account = db.session.get(Account, account_id)
                if account and account.enabled:
                    try:
                        cred = account.get_primary_credential()
                        if cred:
                            service = IPTVService(
                                account.server,
                                cred.username,
                                cred.password,
                                account.user_agent or "okhttp/3.14.9",
                            )
                        else:
                            service = IPTVService(
                                account.server,
                                account.username,
                                account.password,
                                account.user_agent or "okhttp/3.14.9",
                            )
                        xml_content = service.get_xmltv()
                    except Exception as e:
                        logger.warning(f"Failed to fetch EPG for account {account_id}: {e}")
                        continue

            if not xml_content:
                continue

            # Generate filtered EPG for this account's channels with channel links
            filtered_xml = EpgService.generate_filtered_epg(epg_ids, xml_content, channel_link_map=channel_link_map)

            # Parse and merge into combined result
            try:
                filtered_root = ET.fromstring(filtered_xml)
                for elem in filtered_root:
                    if elem.tag == "channel":
                        all_channel_elements.append(elem)
                    elif elem.tag == "programme":
                        all_programme_elements.append(elem)
            except ET.ParseError as e:
                logger.warning(f"Failed to parse filtered EPG for account {account_id}: {e}")
                continue

        # Add all channel elements first, then programmes
        for elem in all_channel_elements:
            root.append(elem)
        for elem in all_programme_elements:
            root.append(elem)

        return ET.tostring(root, encoding="unicode", xml_declaration=True).encode("utf-8")


def _copy_element(elem: ET.Element) -> ET.Element:
    """
    Deep copy an XML element.

    Args:
        elem: Element to copy

    Returns:
        New element with all attributes and children copied
    """
    new_elem = ET.Element(elem.tag, elem.attrib)
    new_elem.text = elem.text
    new_elem.tail = elem.tail
    for child in elem:
        new_elem.append(_copy_element(child))
    return new_elem
